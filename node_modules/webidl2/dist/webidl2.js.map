{"version":3,"sources":["webpack://WebIDL2/webpack/universalModuleDefinition","webpack://WebIDL2/webpack/bootstrap","webpack://WebIDL2/./lib/error.js","webpack://WebIDL2/./lib/productions/base.js","webpack://WebIDL2/./lib/validators/helpers.js","webpack://WebIDL2/./lib/productions/array-base.js","webpack://WebIDL2/./lib/productions/token.js","webpack://WebIDL2/./lib/productions/extended-attributes.js","webpack://WebIDL2/./lib/productions/type.js","webpack://WebIDL2/./lib/productions/default.js","webpack://WebIDL2/./lib/productions/argument.js","webpack://WebIDL2/./lib/productions/operation.js","webpack://WebIDL2/./lib/productions/attribute.js","webpack://WebIDL2/./lib/productions/helpers.js","webpack://WebIDL2/./lib/tokeniser.js","webpack://WebIDL2/./lib/productions/enum.js","webpack://WebIDL2/./lib/productions/includes.js","webpack://WebIDL2/./lib/productions/typedef.js","webpack://WebIDL2/./lib/productions/callback.js","webpack://WebIDL2/./lib/productions/container.js","webpack://WebIDL2/./lib/productions/constant.js","webpack://WebIDL2/./lib/productions/iterable.js","webpack://WebIDL2/./lib/productions/constructor.js","webpack://WebIDL2/./lib/productions/interface.js","webpack://WebIDL2/./lib/validators/interface.js","webpack://WebIDL2/./lib/productions/mixin.js","webpack://WebIDL2/./lib/productions/field.js","webpack://WebIDL2/./lib/productions/dictionary.js","webpack://WebIDL2/./lib/productions/namespace.js","webpack://WebIDL2/./lib/productions/callback-interface.js","webpack://WebIDL2/./lib/webidl2.js","webpack://WebIDL2/./lib/writer.js","webpack://WebIDL2/./lib/validator.js"],"names":["root","factory","exports","module","define","amd","this","installedModules","__webpack_require__","moduleId","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","source","position","current","message","kind","level","autofix","ruleName","sliceTokens","count","slice","Math","max","tokensToText","inputs","precedes","text","map","trivia","join","nextToken","type","length","line","precedingLastLine","splitted","split","lastLine","subsequentTokens","subsequentText","sourceContext","repeat","contextType","context","partial","node","hierarchy","parent","unshift","base","target","result","appendIfExist","contextAsText","bareMessage","sourceName","input","tokens","syntaxError","validationError","token","options","index","Base","defineProperties","writable","json","undefined","inheritance","proto","descMap","getOwnPropertyDescriptors","entries","getPrototypeOf","idlTypeIncludesDictionary","idlType","defs","useNullableInner","union","def","unique","typedefIncludesDictionary","cache","has","set","reference","dictionary","nullable","subtype","ArrayBase","Array","super","tokeniser","consume","tokenName","parser","listName","extAttrValueSyntax","renamedLegacies","Map","assign","ret","autoParenter","secondaryName","open","list","rhsIsList","syntax","toks","error","extAttrListItems","argument_list","close","hasRhs","params","parse","rhsType","extAttr","arg","arguments","validate","push","probe","type_suffix","obj","single_type","typeName","return_type","type_with_extended_attributes","keyType","stringTypes","keyIdlType","separator","valueType","generic_type","primitive_type","typeNameKeywords","generic","typ","or","union_type","extAttrs","Boolean","prefix","postfix","filter","typedef","targetToken","const_value","expression","const_data","negative","start_position","optional","variadic","argumentNameKeywords","default","unconsume","autofixOptionalDictionaryDefaultValue","dictionaryIncludesRequiredField","dict","superdict","members","some","field","required","indexOf","a","isLastRequiredArgument","firstToken","getFirstToken","special","regular","termination","includes","argument","noInherit","readonly","identifier","startsWith","allowDangler","first","items","item","num_type","integer_type","decimal_type","voidToken","stringifier","getLastIndentation","str","lines","match","autofixAddExposedWindow","exposed","existing","test","data","values","sort","x","y","Proxy","isArray","tokenRe","nonRegexTerminals","concat","punctuations","reserved","idl","lastCharIndex","nextChar","charAt","attemptTokenMatch","noFlushTrivia","currentTrivia","pop","lastIndex","WebIDLParseError","punctuation","Error","re","exec","tokenise","candidates","mixin","instance","inheritable","allowedMembers","colon","ea","mem","args","member","async","secondTypeRequired","secondTypeAllowed","argumentAllowed","argsOpen","argsClose","static_member","every","oldConstructors","constructor","autofixConstructor","factoryFunctions","named","constructors","opNames","Set","getOperations","op","partials","mixins","mixinMap","ext","additions","forEachExtension","addition","add","existings","checkInterfaceMemberDuplication","interfaceDef","constructorExtAttr","indentation","memberIndent","parentTrivia","indentCh","getMemberIndentation","constructorOp","existingIndex","array","predicate","reverse","findIndex","findLastIndex","splice","removed","trim","callback","parseByTokens","interface_","opts","definition","res","eof","concrete","definitions","noop","templates","wrap","nameless","extendedAttribute","extendedAttributeReference","write","ast","ts","raw","unescaped","wrapper","reference_token","name_token","type_body","it","ref","extended_attributes","default_","extended_attribute_listitem","make_ext_at","id","endsWith","eats","container","inh","iterate","iterable_like","table","interface","namespace","operation","body","attribute","const","enum","v","iterable","maplike","setlike","things","results","thing","dispatch","getMixinMap","all","include","validateIterable","duplicates","WeakMap","groupDefinitions","dup","checkDuplicatedNames","flat"],"mappings":"CAAA,SAA2CA,EAAMC,GAC1B,iBAAZC,SAA0C,iBAAXC,OACxCA,OAAOD,QAAUD,IACQ,mBAAXG,QAAyBA,OAAOC,IAC9CD,OAAO,GAAIH,GACe,iBAAZC,QACdA,QAAiB,QAAID,IAErBD,EAAc,QAAIC,IARpB,CASGK,MAAM,WACT,O,YCTE,IAAIC,EAAmB,GAGvB,SAASC,EAAoBC,GAG5B,GAAGF,EAAiBE,GACnB,OAAOF,EAAiBE,GAAUP,QAGnC,IAAIC,EAASI,EAAiBE,GAAY,CACzCC,EAAGD,EACHE,GAAG,EACHT,QAAS,IAUV,OANAU,EAAQH,GAAUI,KAAKV,EAAOD,QAASC,EAAQA,EAAOD,QAASM,GAG/DL,EAAOQ,GAAI,EAGJR,EAAOD,QA0Df,OArDAM,EAAoBM,EAAIF,EAGxBJ,EAAoBO,EAAIR,EAGxBC,EAAoBQ,EAAI,SAASd,EAASe,EAAMC,GAC3CV,EAAoBW,EAAEjB,EAASe,IAClCG,OAAOC,eAAenB,EAASe,EAAM,CAAEK,YAAY,EAAMC,IAAKL,KAKhEV,EAAoBgB,EAAI,SAAStB,GACX,oBAAXuB,QAA0BA,OAAOC,aAC1CN,OAAOC,eAAenB,EAASuB,OAAOC,YAAa,CAAEC,MAAO,WAE7DP,OAAOC,eAAenB,EAAS,aAAc,CAAEyB,OAAO,KAQvDnB,EAAoBoB,EAAI,SAASD,EAAOE,GAEvC,GADU,EAAPA,IAAUF,EAAQnB,EAAoBmB,IAC/B,EAAPE,EAAU,OAAOF,EACpB,GAAW,EAAPE,GAA8B,iBAAVF,GAAsBA,GAASA,EAAMG,WAAY,OAAOH,EAChF,IAAII,EAAKX,OAAOY,OAAO,MAGvB,GAFAxB,EAAoBgB,EAAEO,GACtBX,OAAOC,eAAeU,EAAI,UAAW,CAAET,YAAY,EAAMK,MAAOA,IACtD,EAAPE,GAA4B,iBAATF,EAAmB,IAAI,IAAIM,KAAON,EAAOnB,EAAoBQ,EAAEe,EAAIE,EAAK,SAASA,GAAO,OAAON,EAAMM,IAAQC,KAAK,KAAMD,IAC9I,OAAOF,GAIRvB,EAAoB2B,EAAI,SAAShC,GAChC,IAAIe,EAASf,GAAUA,EAAO2B,WAC7B,WAAwB,OAAO3B,EAAgB,SAC/C,WAA8B,OAAOA,GAEtC,OADAK,EAAoBQ,EAAEE,EAAQ,IAAKA,GAC5BA,GAIRV,EAAoBW,EAAI,SAASiB,EAAQC,GAAY,OAAOjB,OAAOkB,UAAUC,eAAe1B,KAAKuB,EAAQC,IAGzG7B,EAAoBgC,EAAI,GAIjBhC,EAAoBA,EAAoBiC,EAAI,G,+BC/CrD,SAAS,EAAMC,EAAQC,EAAUC,EAASC,EAASC,GAAM,MAAEC,EAAQ,QAAO,QAAEC,EAAO,SAAEC,GAAa,IAIhG,SAASC,EAAYC,GACnB,OAAOA,EAAQ,EACbT,EAAOU,MAAMT,EAAUA,EAAWQ,GAClCT,EAAOU,MAAMC,KAAKC,IAAIX,EAAWQ,EAAO,GAAIR,GAGhD,SAASY,EAAaC,GAAQ,SAAEC,GAAa,IAC3C,MAAMC,EAAOF,EAAOG,IAAI/B,GAAKA,EAAEgC,OAAShC,EAAED,OAAOkC,KAAK,IAChDC,EAAYpB,EAAOC,GACzB,MAAuB,QAAnBmB,EAAUC,KACLL,EAELD,EACKC,EAAOI,EAAUF,OAEnBF,EAAKN,MAAMU,EAAUF,OAAOI,QAGrC,MACMC,EACsB,QAA1BvB,EAAOC,GAAUoB,KAAiBrB,EAAOC,GAAUsB,KACnDvB,EAAOsB,OAAS,EAAItB,EAAOC,EAAW,GAAGsB,KACzC,EAEIC,EA5DR,SAAkBR,GAChB,MAAMS,EAAWT,EAAKU,MAAM,MAC5B,OAAOD,EAASA,EAASH,OAAS,GA0DRK,CACxBd,EAAaL,GAPG,GAOsB,CAAEO,UAAU,KAG9Ca,EAAmBpB,EAVP,GAWZqB,EAAiBhB,EAAae,GAI9BE,EAAgBN,EAHMK,EAAeH,MAAM,MAAM,GAGS,MADjD,IAAIK,OAAOP,EAAkBF,QAAU,KAGhDU,EAAuB,WAAT5B,EAAoB,QAAU,SAG5C6B,EAAU,GAAG7B,mBAAsBmB,IAFpBvB,EAAOzB,KAAO,OAAOyB,EAAOzB,KAAS,KAC9B2B,GAAWA,EAAQ3B,KAAQ,KAAKyD,OAAiB9B,EAAQgC,QAAU,WAAa,KA5D9G,SAAuBC,GACrB,MAAMC,EAAY,CAACD,GACnB,KAAOA,GAAQA,EAAKE,QAAQ,CAC1B,MAAM,OAAEA,GAAWF,EACnBC,EAAUE,QAAQD,GAClBF,EAAOE,EAET,OAAOD,EAAUnB,IAAIxB,GAfvB,SAAuB8C,EAAMC,GAC3B,IAAIC,EAASF,EAIb,OAHIC,IACFC,GAAU,IAAID,GAETC,EAUmBC,CAAcjD,EAAE4B,KAAM5B,EAAElB,OAAO4C,KAAK,QAqDmDwB,CAAczC,OAAe,QACvD4B,IACvF,MAAO,CACL3B,QAAS,GAAG8B,KAAW9B,IACvByC,YAAazC,EACb8B,UACAV,OACAsB,WAAY7C,EAAOzB,KACnB8B,QACAE,WACAD,UACAwC,MAAOjB,EACPkB,OAAQnB,GAOL,SAASoB,EAAYhD,EAAQC,EAAUC,EAASC,GACrD,OAAO,EAAMH,EAAQC,EAAUC,EAASC,EAAS,UAO5C,SAAS8C,EAAgBC,EAAOhD,EAASK,EAAUJ,EAASgD,EAAU,IAE3E,OADAA,EAAQ5C,SAAWA,EACZ,EAAML,EAAQF,OAAQkD,EAAME,MAAOlD,EAASC,EAAS,aAAcgD,G,4LCvGrE,MAAME,KAMX,aAAY,OAAErD,EAAM,OAAE+C,IACpBrE,OAAO4E,iBAAiB1F,KAAM,CAC5BoC,OAAQ,CAAEf,MAAOe,GACjB+C,OAAQ,CAAE9D,MAAO8D,EAAQQ,UAAU,GACnClB,OAAQ,CAAEpD,MAAO,KAAMsE,UAAU,GACjC3F,KAAM,CAAEqB,MAAOrB,QAInB,SACE,MAAM4F,EAAO,CAAEnC,UAAMoC,EAAWlF,UAAMkF,EAAWC,iBAAaD,GAC9D,IAAIE,EAAQ/F,KACZ,KAAO+F,IAAUjF,OAAOkB,WAAW,CACjC,MAAMgE,EAAUlF,OAAOmF,0BAA0BF,GACjD,IAAK,MAAOpE,EAAKN,KAAUP,OAAOoF,QAAQF,IACpC3E,EAAML,YAAcK,EAAMJ,OAE5B2E,EAAKjE,GAAO3B,KAAK2B,IAGrBoE,EAAQjF,OAAOqF,eAAeJ,GAEhC,OAAOH,GCnBJ,SAASQ,EAA0BC,EAASC,GAAM,iBAAEC,GAAqB,IAC9E,IAAKF,EAAQG,MAAO,CAClB,MAAMC,EAAMH,EAAKI,OAAOzF,IAAIoF,EAAQA,SACpC,IAAKI,EACH,OAEF,GAAiB,YAAbA,EAAIhD,KAAoB,CAC1B,MAAM,0BAAEkD,GAA8BL,EAAKM,MAC3C,GAAID,EAA0BE,IAAIJ,GAGhC,OAAOE,EAA0B1F,IAAIwF,GAEvCH,EAAKM,MAAMD,0BAA0BG,IAAIL,OAAKZ,GAC9C,MAAMhB,EAASuB,EAA0BK,EAAIJ,QAASC,GAEtD,GADAA,EAAKM,MAAMD,0BAA0BG,IAAIL,EAAK5B,GAC1CA,EACF,MAAO,CACLkC,UAAWV,EACXW,WAAYnC,EAAOmC,YAIzB,GAAiB,eAAbP,EAAIhD,OAA0B8C,IAAqBF,EAAQY,UAC7D,MAAO,CACLF,UAAWV,EACXW,WAAYP,GAIlB,IAAK,MAAMS,KAAWb,EAAQa,QAAS,CACrC,MAAMrC,EAASuB,EAA0Bc,EAASZ,GAClD,GAAIzB,EACF,OAAIqC,EAAQV,MACH3B,EAEF,CACLkC,UAAWG,EACXF,WAAYnC,EAAOmC,aC/CpB,MAAMG,kBAAkBC,MAC7B,aAAY,OAAEhF,EAAM,OAAE+C,IACpBkC,QACAvG,OAAO4E,iBAAiB1F,KAAM,CAC5BoC,OAAQ,CAAEf,MAAOe,GACjB+C,OAAQ,CAAE9D,MAAO8D,GACjBV,OAAQ,CAAEpD,MAAO,KAAMsE,UAAU,MCHhC,MAAM,oBAAcF,KAKzB,cAAc6B,EAAW7D,GACvB,MAAO,KACL,MAAMpC,EAAQiG,EAAUC,QAAQ9D,GAChC,GAAIpC,EACF,OAAO,IAAI,YAAM,CAAEe,OAAQkF,EAAUlF,OAAQ+C,OAAQ,CAAE9D,YAK7D,YACE,OAAO,EAASrB,KAAKmF,OAAO9D,MAAMA,QCVtC,SAAS,EAAOiG,EAAWE,GACzB,OAAO,EAAKF,EAAW,CACrBG,OAAQ,YAAMA,OAAOH,EAAWE,GAChCE,SAAUF,EAAY,UAI1B,MAAMG,EAAqB,CAAC,aAAc,UAAW,UAAW,UAU1DC,EAAkB,IAAIC,IAAI,IARD,CAC7B,oBACA,gBACA,cACA,uBACA,eAI0BxE,IAAI1C,GAAQ,CAACA,EAAM,SAASA,IACtD,CAAC,mBAAoB,yBACrB,CAAC,mBAAoB,0BACrB,CAAC,cAAe,6BAkBlB,MAAM,wDAAoC8E,KAIxC,aAAa6B,GACX,MAAMnC,EAAS,CAAE2C,OAAQR,EAAUC,QAAQ,MACrCQ,EAAMC,EAAa,IAAI,gDAA4B,CAAE5F,OAAQkF,EAAUlF,OAAQ+C,YAerF,OAdIA,EAAO2C,SACT3C,EAAO8C,cAAgBX,EAAUC,WAAWI,IAE9CxC,EAAO+C,KAAOZ,EAAUC,QAAQ,KAC5BpC,EAAO+C,MACTH,EAAII,KAAOJ,EAAIK,UAvBrB,SAA0Bd,GACxB,IAAK,MAAMe,KAAUV,EAAoB,CACvC,MAAMW,EAAO,EAAOhB,EAAWe,GAC/B,GAAIC,EAAK5E,OACP,OAAO4E,EAGXhB,EAAUiB,MAAM,uEAkBVC,CAAiBlB,GAEjBmB,EAAcnB,GAChBnC,EAAOuD,MAAQpB,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,yDAChDR,EAAIY,SAAWxD,EAAO8C,eAC/BX,EAAUiB,MAAM,uDAEXR,EAAI/H,KAGb,gBACE,OAAOA,KAAKmF,OAAO2C,SAAW9H,KAAKmF,OAAO8C,cAG5C,cACE,OAAIjI,KAAKoI,UACApI,KAAKmI,KAAK,GAAGhD,OAAO9D,MAAMoC,KAAO,QAEtCzD,KAAKmF,OAAO8C,cACPjI,KAAKmF,OAAO8C,cAAcxE,KAE5B,MAIJ,MAAM,oDAAgCgC,KAI3C,aAAa6B,GACX,MAAM3G,EAAO2G,EAAUC,QAAQ,cAC/B,GAAI5G,EACF,OAAO,IAAI,4CAAwB,CACjCyB,OAAQkF,EAAUlF,OAClB+C,OAAQ,CAAExE,QACViI,OAAQ,gDAA4BC,MAAMvB,KAKhD,aAAY,OAAElF,EAAM,OAAE+C,EAAM,OAAEyD,IAC5BvB,MAAM,CAAEjF,SAAQ+C,WAChByD,EAAOnE,OAASzE,KAChBc,OAAOC,eAAef,KAAM,SAAU,CAAEqB,MAAOuH,IAGjD,WACE,MAAO,qBAET,WACE,OAAO5I,KAAKmF,OAAOxE,KAAKU,MAE1B,UACE,MAAQyH,QAASrF,EAAI,OAAE0B,EAAM,KAAEgD,GAASnI,KAAK4I,OAC7C,OAAKnF,EAIE,CAAEA,OAAMpC,MADDrB,KAAK4I,OAAOR,UAAYD,EAAO,EAAShD,EAAO8C,cAAc5G,QAFlE,KAKX,gBACE,MAAM,UAAE+G,EAAS,KAAED,GAASnI,KAAK4I,OACjC,OAAKT,GAAQC,EACJ,GAEFD,EAGT,UAAU7B,GACR,MAAM,KAAE3F,GAASX,KACjB,GAAa,4BAATW,EAAoC,CACtC,MAAM4B,EAAU,sOAIV8C,EAAgBrF,KAAKmF,OAAOxE,KAAMX,KAAM,uBAAwBuC,EAAS,CAAEE,MAAO,iBACnF,GAAImF,EAAgBf,IAAIlG,GAAO,CACpC,MAAM4B,EAAU,MAAM5B,yEACAiH,EAAgB3G,IAAIN,oHAGpC0E,EAAgBrF,KAAKmF,OAAOxE,KAAMX,KAAM,iBAAkBuC,EAAS,CACvEE,MAAO,UACPC,SAY+BqG,EAZQ/I,KAatC,KACL,MAAM,KAAEW,GAASoI,EACjBA,EAAQ5D,OAAOxE,KAAKU,MAAQuG,EAAgB3G,IAAIN,GACnC,gBAATA,IACFoI,EAAQH,OAAOzD,OAAS,QAL9B,IAAuC4D,EATnC,IAAK,MAAMC,KAAOhJ,KAAKiJ,gBACdD,EAAIE,SAAS5C,IAoBnB,MAAM,+CAA2Ba,UAItC,aAAaG,GACX,MAAMnC,EAAS,GAEf,GADAA,EAAO+C,KAAOZ,EAAUC,QAAQ,MAC3BpC,EAAO+C,KAAM,OAAO,IAAI,uCAAmB,IAChD,MAAMH,EAAM,IAAI,uCAAmB,CAAE3F,OAAQkF,EAAUlF,OAAQ+C,WAY/D,OAXA4C,EAAIoB,QAAQ,EAAK7B,EAAW,CAC1BG,OAAQ,4CAAwBoB,MAChCnB,SAAU,wBAEZvC,EAAOuD,MAAQpB,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,kDACpDR,EAAIrE,QACP4D,EAAUiB,MAAM,qCAEdjB,EAAU8B,MAAM,MAClB9B,EAAUiB,MAAM,kEAEXR,EAGT,UAAUzB,GACR,IAAK,MAAMyC,KAAW/I,WACb+I,EAAQG,SAAS5C,IChJ9B,SAAS+C,EAAY/B,EAAWgC,GAC9B,MAAMrC,EAAWK,EAAUC,QAAQ,KAC/BN,IACFqC,EAAInE,OAAO8B,SAAWA,GAEpBK,EAAU8B,MAAM,MAAM9B,EAAUiB,MAAM,iCAO5C,SAASgB,EAAYjC,EAAWkC,GAC9B,IAAIzB,EArDN,SAAsBT,EAAWkC,GAC/B,MAAM7E,EAAO2C,EAAUC,QAAQ,cAAe,kBAAmB,UAAW,WAAY,UACxF,IAAK5C,EACH,OAEF,MAAMoD,EAAMC,EAAa,IAAI,UAAK,CAAE5F,OAAQkF,EAAUlF,OAAQ+C,OAAQ,CAAER,WAExE,OADAoD,EAAI5C,OAAO+C,KAAOZ,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,4BAA4B5D,EAAKlB,MACrFkB,EAAKlB,MACX,IAAK,UAAW,CACV6D,EAAU8B,MAAM,MAAM9B,EAAUiB,MAAM,+CAC1C,MAAMrB,EAAUuC,EAAYnC,EAAWkC,IAAalC,EAAUiB,MAAM,2BACpER,EAAIb,QAAQiC,KAAKjC,GACjB,MAEF,IAAK,WACL,IAAK,cACL,IAAK,kBAAmB,CACtB,MAAMA,EAAUwC,EAA8BpC,EAAWkC,IAAalC,EAAUiB,MAAM,WAAW5D,EAAKlB,gBACtGsE,EAAIb,QAAQiC,KAAKjC,GACjB,MAEF,IAAK,SAAU,CACTI,EAAU8B,MAAM,MAAM9B,EAAUiB,MAAM,6CAC1C,MAAMoB,EAAUrC,EAAUC,WAAWqC,IAAgBtC,EAAUiB,MAAM,8BAA8BqB,EAAYrG,KAAK,OAC9GsG,EAAa,IAAI,UAAK,CAAEzH,OAAQkF,EAAUlF,OAAQ+C,OAAQ,CAAER,KAAMgF,KACxEE,EAAW1E,OAAO2E,UAAYxC,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,uCACxEsB,EAAWpG,KAAO+F,EAClB,MAAMO,EAAYL,EAA8BpC,EAAWkC,IAAalC,EAAUiB,MAAM,qCACxFR,EAAIb,QAAQiC,KAAKU,EAAYE,GAC7B,OAKJ,OAFKhC,EAAI1B,SAASiB,EAAUiB,MAAM,8BAA8B5D,EAAKlB,MACrEsE,EAAI5C,OAAOuD,MAAQpB,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,iCAAiC5D,EAAKlB,MAC5FsE,EAAI/H,KAmBDgK,CAAa1C,EAAWkC,IAAaS,EAAe3C,GAC9D,IAAKS,EAAK,CACR,MAAMpD,EAAO2C,EAAUC,QAAQ,gBAAiBqC,KAAgBM,GAChE,IAAKvF,EACH,OAEFoD,EAAM,IAAI,UAAK,CAAE3F,OAAQkF,EAAUlF,OAAQ+C,OAAQ,CAAER,UACjD2C,EAAU8B,MAAM,MAAM9B,EAAUiB,MAAM,4BAA4B5D,EAAKtD,OAQ7E,MANoB,YAAhB0G,EAAIoC,SAAyB7C,EAAU8B,MAAM,MAC/C9B,EAAUiB,MAAM,mCAElBR,EAAItE,KAAO+F,GAAY,KACvBH,EAAY/B,EAAWS,GACnBA,EAAId,UAA4B,QAAhBc,EAAI1B,SAAmBiB,EAAUiB,MAAM,sCACpDR,EAgCF,MAAM,kBAAatC,KAKxB,aAAa6B,EAAWkC,GACtB,OAAOD,EAAYjC,EAAWkC,IA/BlC,SAAoBlC,EAAW7D,GAC7B,MAAM0B,EAAS,GAEf,GADAA,EAAO+C,KAAOZ,EAAUC,QAAQ,MAC3BpC,EAAO+C,KAAM,OAClB,MAAMH,EAAMC,EAAa,IAAI,UAAK,CAAE5F,OAAQkF,EAAUlF,OAAQ+C,YAE9D,IADA4C,EAAItE,KAAOA,GAAQ,OACN,CACX,MAAM2G,EAAMV,EAA8BpC,IAAcA,EAAUiB,MAAM,wDACpD,QAAhB6B,EAAI/D,SAAmBiB,EAAUiB,MAAM,iDACvB,YAAhB6B,EAAID,SAAuB7C,EAAUiB,MAAM,qDAC/CR,EAAIb,QAAQiC,KAAKiB,GACjB,MAAMC,EAAK/C,EAAUC,QAAQ,MAC7B,IAAI8C,EAGC,MAFHD,EAAIjF,OAAO2E,UAAYO,EAS3B,OALItC,EAAI1B,QAAQ3C,OAAS,GACvB4D,EAAUiB,MAAM,kEAElBpD,EAAOuD,MAAQpB,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,2BACzDc,EAAY/B,EAAWS,GAChBA,EAAI/H,KASkCsK,CAAWhD,EAAWkC,GAGnE,aAAY,OAAEpH,EAAM,OAAE+C,IACpBkC,MAAM,CAAEjF,SAAQ+C,WAChBrE,OAAOC,eAAef,KAAM,UAAW,CAAEqB,MAAO,GAAIsE,UAAU,IAC9D3F,KAAKuK,SAAW,IAAI,uCAAmB,IAGzC,cACE,OAAIvK,KAAKkH,QAAQxD,QAAU1D,KAAKmF,OAAOR,KAC9B3E,KAAKmF,OAAOR,KAAKtD,MAEnB,GAET,eACE,OAAOmJ,QAAQxK,KAAKmF,OAAO8B,UAE7B,YACE,OAAOuD,QAAQxK,KAAKkH,QAAQxD,UAAY1D,KAAKmF,OAAOR,KAEtD,cACE,GAAI3E,KAAKkH,QAAQxD,OACf,OAAO1D,KAAKkH,QAQd,OAAO,EALM,CACXlH,KAAKmF,OAAOsF,OACZzK,KAAKmF,OAAOR,KACZ3E,KAAKmF,OAAOuF,SACZC,OAAOrJ,GAAKA,GAAG+B,IAAI/B,GAAKA,EAAED,OAAOkC,KAAK,MAI1C,UAAU+C,GAGR,SAFOtG,KAAKuK,SAASrB,SAAS5C,GAET,SAAjBtG,KAAKqG,QAAoB,CAC3B,MAAM9D,EAAU,sJAGV8C,EAAgBrF,KAAKmF,OAAOR,KAAM3E,KAAM,eAAgBuC,EAAS,CACrEG,SAiCae,EAjCQzD,KAkCpB,KACLyD,EAAK0B,OAAOR,KAAKtD,MAAQ,gBAF7B,IAAqBoC,EAzBjB,MAAMmH,GAAW5K,KAAKwG,OAASF,EAAKI,OAAOzF,IAAIjB,KAAKqG,SAC9CzB,EACJ5E,KAAKwG,MAAQxG,KACZ4K,GAA4B,YAAjBA,EAAQnH,KAAsBmH,EAAQvE,aAClDR,EACF,GAAIjB,GAAU5E,KAAKiH,SAAU,CAE3B,MAAM,UAAEF,GAAcX,EAA0BxB,EAAQ0B,IAAS,GACjE,GAAIS,EAAW,CACb,MAAM8D,GAAe7K,KAAKwG,MAAQO,EAAY/G,MAAMmF,OAAOR,KACrDpC,EAAU,yDACV8C,EAAgBwF,EAAa7K,KAAM,yBAA0BuC,SAIrE,IAAK,MAAM2E,KAAWlH,KAAKkH,cAClBA,EAAQgC,SAAS5C,ICpLzB,MAAM,wBAAgBb,KAI3B,aAAa6B,GACX,MAAMQ,EAASR,EAAUC,QAAQ,KACjC,IAAKO,EACH,OAAO,KAET,MAAMrB,EAAMqE,EAAYxD,IAAcA,EAAUC,QAAQ,SAAU,OAAQ,IAAK,MAAQD,EAAUiB,MAAM,wBACjGwC,EAAa,CAACtE,GACpB,GAAiB,MAAbA,EAAIhD,KAAc,CACpB,MAAMiF,EAAQpB,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,wCACxDwC,EAAW5B,KAAKT,QACX,GAAiB,MAAbjC,EAAIhD,KAAc,CAC3B,MAAMiF,EAAQpB,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,0CACxDwC,EAAW5B,KAAKT,GAElB,OAAO,IAAI,gBAAQ,CAAEtG,OAAQkF,EAAUlF,OAAQ+C,OAAQ,CAAE2C,UAAUiD,eAGrE,aAAY,OAAE3I,EAAM,OAAE+C,EAAM,WAAE4F,IAC5B1D,MAAM,CAAEjF,SAAQ+C,WAChB4F,EAAWtG,OAASzE,KACpBc,OAAOC,eAAef,KAAM,aAAc,CAAEqB,MAAO0J,IAGrD,WACE,OAAOC,EAAWhL,KAAK+K,WAAW,IAAItH,KAExC,YACE,OAAOuH,EAAWhL,KAAK+K,WAAW,IAAI1J,MAExC,eACE,OAAO2J,EAAWhL,KAAK+K,WAAW,IAAIE,UC3BnC,MAAM,0BAAiBxF,KAI5B,aAAa6B,GACX,MAAM4D,EAAiB5D,EAAUjF,SAE3B8C,EAAS,GACT4C,EAAMC,EAAa,IAAI,kBAAS,CAAE5F,OAAQkF,EAAUlF,OAAQ+C,YAIlE,OAHA4C,EAAIwC,SAAW,uCAAmB1B,MAAMvB,GACxCnC,EAAOgG,SAAW7D,EAAUC,QAAQ,YACpCQ,EAAI1B,QAAUqD,EAA8BpC,EAAW,iBAClDS,EAAI1B,SAGJlB,EAAOgG,WACVhG,EAAOiG,SAAW9D,EAAUC,QAAQ,QAEtCpC,EAAOxE,KAAO2G,EAAUC,QAAQ,gBAAiB8D,GAC5ClG,EAAOxE,MAGZoH,EAAIuD,QAAUnG,EAAOgG,SAAW,gBAAQtC,MAAMvB,GAAa,KACpDS,EAAI/H,MAHFsH,EAAUiE,UAAUL,IAPpB5D,EAAUiE,UAAUL,GAa/B,WACE,MAAO,WAET,eACE,QAASlL,KAAKmF,OAAOgG,SAEvB,eACE,QAASnL,KAAKmF,OAAOiG,SAEvB,WACE,OAAO,EAASpL,KAAKmF,OAAOxE,KAAKU,OAMnC,UAAUiF,SACDtG,KAAKqG,QAAQ6C,SAAS5C,GAC7B,MAAMzB,EAASuB,EAA0BpG,KAAKqG,QAASC,EAAM,CAAEC,kBAAkB,IACjF,GAAI1B,EACF,GAAI7E,KAAKqG,QAAQY,SAAU,CACzB,MAAM1E,EAAU,iDACV8C,EAAgBrF,KAAKmF,OAAOxE,KAAMX,KAAM,uBAAwBuC,QACjE,GAAKvC,KAAKmL,UAOV,IAAKnL,KAAKsL,QAAS,CACxB,MAAM/I,EAAU,yEACV8C,EAAgBrF,KAAKmF,OAAOxE,KAAMX,KAAM,mBAAoBuC,EAAS,CACzEG,QAAS8I,EAAsCxL,cATjD,GAAIA,KAAKyE,SNAV,SAASgH,EAAgCC,EAAMpF,GACpD,GAAIA,EAAKM,MAAM6E,gCAAgC5E,IAAI6E,GACjD,OAAOpF,EAAKM,MAAM6E,gCAAgCxK,IAAIyK,GAGxD,GADApF,EAAKM,MAAM6E,gCAAgC3E,IAAI4E,OAAM7F,GACjD6F,EAAK5F,YAAa,CACpB,MAAM6F,EAAYrF,EAAKI,OAAOzF,IAAIyK,EAAK5F,aACvC,IAAK6F,EACH,OAAO,EAET,GAAIF,EAAgCE,EAAWrF,GAC7C,OAAO,EAGX,MAAMzB,EAAS6G,EAAKE,QAAQC,KAAKC,GAASA,EAAMC,UAEhD,OADAzF,EAAKM,MAAM6E,gCAAgC3E,IAAI4E,EAAM7G,GAC9CA,EMhBmB4G,CAAgC5G,EAAOmC,WAAYV,IAmB/E,SAAgC0C,GAC9B,MAAMb,EAAOa,EAAIvE,OAAOwE,WAAaD,EAAIvE,OAAO0D,KAC1C3C,EAAQ2C,EAAK6D,QAAQhD,GAE3B,OADuBb,EAAKrF,MAAM0C,EAAQ,GAAGqG,KAAKI,IAAMA,EAAEd,UAtB4Be,CAAuBlM,MAAO,CAC5G,MAAMuC,EAAU,0EACV8C,EAAgBrF,KAAKmF,OAAOxE,KAAMX,KAAM,oBAAqBuC,EAAS,CAC1EG,SA0BkCsG,EA1BYhJ,KA2BjD,KACL,MAAMmM,EAAaC,EAAcpD,EAAI3C,SACrC2C,EAAI7D,OAAOgG,SAAW,CAAE1H,KAAM,WAAYpC,MAAO,WAAYiC,OAAQ6I,EAAW7I,QAChF6I,EAAW7I,OAAS,IACpBkI,EAAsCxC,EAAtCwC,OALJ,IAA8CxC,GAY9C,SAASwC,EAAsCxC,GAC7C,MAAO,KACLA,EAAIsC,QAAU,gBAAQzC,MAAM,IAAI,oBAAU,WCnGvC,MAAM,4BAAkBpD,KAS7B,aAAa6B,GAAW,QAAE+E,EAAO,QAAEC,GAAY,IAC7C,MAAMnH,EAAS,CAAEkH,WACXtE,EAAMC,EAAa,IAAI,oBAAU,CAAE5F,OAAQkF,EAAUlF,OAAQ+C,YACnE,OAAIkH,GAA6B,gBAAlBA,EAAQhL,QACrB8D,EAAOoH,YAAcjF,EAAUC,QAAQ,KACnCpC,EAAOoH,cACTxE,EAAIkB,UAAY,GACTlB,IAGNsE,GAAYC,IACfnH,EAAOkH,QAAU/E,EAAUC,QAAQ,SAAU,SAAU,YAEzDQ,EAAI1B,QAAUoD,EAAYnC,IAAcA,EAAUiB,MAAM,uBACxDpD,EAAOxE,KAAO2G,EAAUC,QAAQ,aAAc,YAC9CpC,EAAO+C,KAAOZ,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,qBACxDR,EAAIkB,UAAYR,EAAcnB,GAC9BnC,EAAOuD,MAAQpB,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,0BACzDpD,EAAOoH,YAAcjF,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,wCACxDR,EAAI/H,MAGb,WACE,MAAO,YAET,WACE,MAAM,KAAEW,GAASX,KAAKmF,OACtB,OAAKxE,EAGE,EAASA,EAAKU,OAFZ,GAIX,cACE,OAAKrB,KAAKmF,OAAOkH,QAGVrM,KAAKmF,OAAOkH,QAAQhL,MAFlB,GAKX,UAAUiF,GACR,IAAKtG,KAAKW,MAAQ,CAAC,GAAI,UAAU6L,SAASxM,KAAKqM,SAAU,CACvD,MAAM9J,EAAU,qFACV8C,EAAgBrF,KAAKmF,OAAO+C,KAAMlI,KAAM,gBAAiBuC,GAE7DvC,KAAKqG,gBACArG,KAAKqG,QAAQ6C,SAAS5C,IAE/B,IAAK,MAAMmG,KAAYzM,KAAKiJ,gBACnBwD,EAASvD,SAAS5C,IC1DxB,MAAM,4BAAkBb,KAI7B,aAAa6B,GAAW,QAAE+E,EAAO,UAAEK,GAAY,EAAK,SAAEC,GAAW,GAAU,IACzE,MAAMzB,EAAiB5D,EAAUjF,SAC3B8C,EAAS,CAAEkH,WACXtE,EAAMC,EAAa,IAAI,oBAAU,CAAE5F,OAAQkF,EAAUlF,OAAQ+C,YAYnE,GAXKkH,GAAYK,IACfvH,EAAOkH,QAAU/E,EAAUC,QAAQ,YAEjB,YAAhBQ,EAAIsE,SAAyB/E,EAAU8B,MAAM,aAC/C9B,EAAUiB,MAAM,4CAElBpD,EAAOwH,SAAWrF,EAAUC,QAAQ,YAChCoF,IAAaxH,EAAOwH,UAAYrF,EAAU8B,MAAM,cAClD9B,EAAUiB,MAAM,+CAElBpD,EAAOR,KAAO2C,EAAUC,QAAQ,aAC3BpC,EAAOR,KAAZ,CAKA,OADAoD,EAAI1B,QAAUqD,EAA8BpC,EAAW,mBAAqBA,EAAUiB,MAAM,0BACpFR,EAAI1B,QAAQ8D,SAClB,IAAK,WACL,IAAK,SAAU7C,EAAUiB,MAAM,4BAA4BR,EAAI1B,QAAQ8D,iBAIzE,OAFAhF,EAAOxE,KAAO2G,EAAUC,QAAQ,aAAc,QAAS,aAAeD,EAAUiB,MAAM,0BACtFpD,EAAOoH,YAAcjF,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,wCACxDR,EAAI/H,KAVTsH,EAAUiE,UAAUL,GAaxB,WACE,MAAO,YAET,cACE,OAAKlL,KAAKmF,OAAOkH,QAGVrM,KAAKmF,OAAOkH,QAAQhL,MAFlB,GAIX,eACE,QAASrB,KAAKmF,OAAOwH,SAEvB,WACE,OAAO,EAAS3M,KAAKmF,OAAOxE,KAAKU,OAGnC,UAAUiF,SACDtG,KAAKuK,SAASrB,SAAS5C,SACvBtG,KAAKqG,QAAQ6C,SAAS5C,IC5C1B,SAAS,EAASsG,GACvB,OAAOA,EAAWC,WAAW,KAAOD,EAAW9J,MAAM,GAAK8J,EAWrD,SAAS,EAAKtF,GAAW,OAAEG,EAAM,aAAEqF,EAAY,SAAEpF,EAAW,SACjE,MAAMqF,EAAQtF,EAAOH,GACrB,IAAKyF,EACH,MAAO,GAETA,EAAM5H,OAAO2E,UAAYxC,EAAUC,QAAQ,KAC3C,MAAMyF,EAAQ,CAACD,GACf,KAAOA,EAAM5H,OAAO2E,WAAW,CAC7B,MAAMmD,EAAOxF,EAAOH,GACpB,IAAK2F,EAAM,CACJH,GACHxF,EAAUiB,MAAM,qBAAqBb,GAEvC,MAIF,GAFAuF,EAAK9H,OAAO2E,UAAYxC,EAAUC,QAAQ,KAC1CyF,EAAM7D,KAAK8D,IACNA,EAAK9H,OAAO2E,UAAW,MAE9B,OAAOkD,EAMF,SAASlC,EAAYxD,GAC1B,OAAOA,EAAUC,QAAQ,OAAQ,QAAS,WAAY,YAAa,MAAO,UAAW,WAQhF,SAASyD,GAAW,KAAEvH,EAAI,MAAEpC,IACjC,OAAQoC,GACN,IAAK,OACL,IAAK,QACH,MAAO,CAAEA,KAAM,UAAWpC,MAAgB,SAAToC,GACnC,IAAK,WACL,IAAK,YACH,MAAO,CAAEA,KAAM,WAAYwH,SAAUxH,EAAKoJ,WAAW,MACvD,IAAK,IACH,MAAO,CAAEpJ,KAAM,WAAYpC,MAAO,IACpC,IAAK,IACH,MAAO,CAAEoC,KAAM,cACjB,IAAK,UACL,IAAK,UACH,MAAO,CAAEA,KAAM,SAAUpC,SAC3B,IAAK,SACH,MAAO,CAAEoC,KAAM,SAAUpC,MAAOA,EAAMyB,MAAM,GAAI,IAClD,QACE,MAAO,CAAEW,SAOR,SAASwG,EAAe3C,GAoB7B,MAAM,OAAElF,GAAWkF,EACb4F,EApBN,WACE,MAAMzC,EAASnD,EAAUC,QAAQ,YAC3B5C,EAAO2C,EAAUC,QAAQ,QAAS,QACxC,GAAI5C,EAAM,CACR,MAAM+F,EAAUpD,EAAUC,QAAQ,QAClC,OAAO,IAAI,UAAK,CAAEnF,SAAQ+C,OAAQ,CAAEsF,SAAQ9F,OAAM+F,aAEhDD,GAAQnD,EAAUiB,MAAM,gCAab4E,IAVjB,WACE,MAAM1C,EAASnD,EAAUC,QAAQ,gBAC3B5C,EAAO2C,EAAUC,QAAQ,QAAS,UACxC,GAAI5C,EACF,OAAO,IAAI,UAAK,CAAEvC,SAAQ+C,OAAQ,CAAEsF,SAAQ9F,UAE1C8F,GAAQnD,EAAUiB,MAAM,8BAIc6E,GAC5C,GAAIF,EAAU,OAAOA,EACrB,MAAMvI,EAAO2C,EAAUC,QAAQ,UAAW,OAAQ,QAAS,aAC3D,OAAI5C,EACK,IAAI,UAAK,CAAEvC,SAAQ+C,OAAQ,CAAER,eADtC,EAQK,SAAS8D,EAAcnB,GAC5B,OAAO,EAAKA,EAAW,CAAEG,OAAQ,kBAASoB,MAAOnB,SAAU,mBAOtD,SAASgC,EAA8BpC,EAAWkC,GACvD,MAAMe,EAAW,uCAAmB1B,MAAMvB,GACpCS,EAAM,UAAKc,MAAMvB,EAAWkC,GAElC,OADIzB,IAAKC,EAAaD,GAAKwC,SAAWA,GAC/BxC,EAOF,SAAS0B,EAAYnC,EAAWkC,GACrC,MAAMY,EAAM,UAAKvB,MAAMvB,EAAWkC,GAAY,eAC9C,GAAIY,EACF,OAAOA,EAET,MAAMiD,EAAY/F,EAAUC,QAAQ,QACpC,GAAI8F,EAAW,CACb,MAAMtF,EAAM,IAAI,UAAK,CAAE3F,OAAQkF,EAAUlF,OAAQ+C,OAAQ,CAAER,KAAM0I,KAEjE,OADAtF,EAAItE,KAAO,cACJsE,GAOJ,SAASuF,EAAYhG,GAC1B,MAAM+E,EAAU/E,EAAUC,QAAQ,eAClC,GAAK8E,EAIL,OAHe,oBAAUxD,MAAMvB,EAAW,CAAE+E,aAC1C,oBAAUxD,MAAMvB,EAAW,CAAE+E,aAC7B/E,EAAUiB,MAAM,4BAOb,SAASgF,EAAmBC,GACjC,MAAMC,EAAQD,EAAI1J,MAAM,MAExB,GAAI2J,EAAM/J,OAAQ,CAChB,MAAMgK,EAAQD,EAAMA,EAAM/J,OAAS,GAAGgK,MAAM,QAC5C,GAAIA,EACF,OAAOA,EAAM,GAGjB,MAAO,GAgBF,SAASC,EAAwBlH,GACtC,MAAO,KACL,GAAIA,EAAI8D,SAAS7G,OAAO,CACtB,MAAM4D,EAAY,IAAI,oBAAU,mBAC1BsG,EAAU,4CAAwB/E,MAAMvB,GAC9CsG,EAAQzI,OAAO2E,UAAYxC,EAAUC,QAAQ,KAC7C,MAAMsG,EAAWpH,EAAI8D,SAAS,GACzB,MAAMuD,KAAKD,EAAS1I,OAAOxE,KAAK2C,UACnCuK,EAAS1I,OAAOxE,KAAK2C,OAAS,IAAIuK,EAAS1I,OAAOxE,KAAK2C,QAEzDmD,EAAI8D,SAAS7F,QAAQkJ,OAChB,CACL5F,EAAavB,GAAK8D,SAAW,uCAAmB1B,MAAM,IAAI,oBAAU,qBACpE,MAAMvF,EAASmD,EAAItB,OAAOR,KAAKrB,OAC/BmD,EAAI8D,SAASpF,OAAO+C,KAAK5E,OAASA,EAClCmD,EAAItB,OAAOR,KAAKrB,OAAS,KAAKiK,EAAmBjK,KAShD,SAAS8I,EAAc2B,GAC5B,GAAIA,EAAKxD,SAAS7G,OAChB,OAAOqK,EAAKxD,SAASpF,OAAO+C,KAE9B,GAAkB,cAAd6F,EAAKtK,OAAyBsK,EAAK1B,QACrC,OAAOD,EAAc2B,EAAK1H,SAG5B,OADevF,OAAOkN,OAAOD,EAAK5I,QAAQ8I,KAAK,CAACC,EAAGC,IAAMD,EAAE1I,MAAQ2I,EAAE3I,OACvD,GAwBT,SAASwC,EAAa+F,EAAMtJ,GAKjC,OAJKA,IAEHA,EAASsJ,GAENA,EAKE,IAAIK,MAAML,EAAM,CACrB,IAAInJ,EAAQ1C,GACV,MAAMb,EAAQuD,EAAO1C,GACrB,OAAIkF,MAAMiH,QAAQhN,GAGT2G,EAAa3G,EAAOuD,GAEtBvD,GAET,IAAIuD,EAAQ1C,EAAGb,GAEb,GADAuD,EAAO1C,GAAKb,GACPA,EACH,OAAO,EACF,GAAI+F,MAAMiH,QAAQhN,GAEvB,IAAK,MAAM4L,KAAQ5L,OACU,IAAhB4L,EAAKxI,SACdwI,EAAKxI,OAASA,aAGe,IAAjBpD,EAAMoD,SACtBpD,EAAMoD,OAASA,GAEjB,OAAO,KA1BFsJ,ECpPX,MAAMO,EAAU,CAGd,QAAW,sGACX,QAAW,8CACX,WAAc,+BACd,OAAU,WACV,WAAc,cACd,QAAW,gDACX,MAAS,wBAGEpE,EAAmB,CAC9B,cACA,WACA,YACA,aACA,aACA,aACA,cACA,cACA,oBACA,eACA,eACA,MACA,SACA,UAGWN,EAAc,CACzB,aACA,YACA,aAGWyB,EAAuB,CAClC,QACA,YACA,WACA,QACA,cACA,UACA,aACA,OACA,SACA,WACA,UACA,YACA,WACA,UACA,YACA,UACA,WACA,UACA,SACA,SACA,cACA,UACA,gBAGIkD,EAAoB,CACxB,YACA,cACA,WACA,MACA,kBACA,UACA,UACA,OACA,SACA,QACA,QACA,OACA,QACA,OACA,QACA,WACA,KACA,WACA,SACA,WACA,QACA,OACA,YACA,WACA,QACAC,OAAOnD,EAAsBzB,EAAaM,GAEtCuE,EAAe,CACnB,IACA,IACA,IACA,MACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KAGIC,EAAW,CAEf,eACA,WACA,aAoGK,MAAM,oBAIX,YAAYC,GACV3O,KAAKoC,OAlGT,SAAkBoL,GAChB,MAAMrI,EAAS,GACf,IAAIyJ,EAAgB,EAChBtL,EAAS,GACTK,EAAO,EACP6B,EAAQ,EACZ,KAAOoJ,EAAgBpB,EAAI9J,QAAQ,CACjC,MAAMmL,EAAWrB,EAAIsB,OAAOF,GAC5B,IAAI/J,GAAU,EAQd,GANI,YAAYiJ,KAAKe,GACnBhK,EAASkK,EAAkB,aAAc,CAAEC,eAAe,IACpC,MAAbH,IACThK,EAASkK,EAAkB,UAAW,CAAEC,eAAe,MAGzC,IAAZnK,EAAe,CACjB,MAAMoK,EAAgB9J,EAAO+J,MAAM7N,MACnCsC,IAASsL,EAAcvB,MAAM,QAAU,IAAIhK,OAC3CJ,GAAU2L,EACVzJ,GAAS,OACJ,GAAI,iBAAiBsI,KAAKe,IAK/B,GAJAhK,EAASkK,EAAkB,YACX,IAAZlK,IACFA,EAASkK,EAAkB,aAEb,IAAZlK,EAAe,CACjBA,EAASkK,EAAkB,cAC3B,MAAMI,EAAYhK,EAAOzB,OAAS,EAC5B4B,EAAQH,EAAOgK,GACrB,IAAgB,IAAZtK,EAAe,CACjB,GAAI6J,EAASlC,SAASlH,EAAMjE,OAAQ,CAClC,MAAMkB,EAAa,EAAS+C,EAAMjE,OAAlB,kDAChB,MAAM,IAAI+N,iBAAiBhK,EAAYD,EAAQgK,EAAW,KAAM5M,IACvDgM,EAAkB/B,SAASlH,EAAMjE,SAC1CiE,EAAM7B,KAAO6B,EAAMjE,aAIH,MAAbwN,IACThK,EAASkK,EAAkB,WAG7B,IAAK,MAAMM,KAAeZ,EACxB,GAAIjB,EAAIX,WAAWwC,EAAaT,GAAgB,CAC9CzJ,EAAOgE,KAAK,CAAE1F,KAAM4L,EAAahO,MAAOgO,EAAa/L,SAAQK,OAAM6B,UACnElC,EAAS,GACTsL,GAAiBS,EAAY3L,OAC7BmB,EAAS+J,EACT,MAQJ,IAHgB,IAAZ/J,IACFA,EAASkK,EAAkB,WAEb,IAAZlK,EACF,MAAM,IAAIyK,MAAM,gCAElBV,EAAgB/J,EAChBW,GAAS,EAUX,OANAL,EAAOgE,KAAK,CACV1F,KAAM,MACNpC,MAAO,GACPiC,WAGK6B,EAOP,SAAS4J,EAAkBtL,GAAM,cAAEuL,GAAkB,IACnD,MAAMO,EAAKjB,EAAQ7K,GACnB8L,EAAGJ,UAAYP,EACf,MAAM/J,EAAS0K,EAAGC,KAAKhC,GACvB,OAAI3I,GACFM,EAAOgE,KAAK,CAAE1F,OAAMpC,MAAOwD,EAAO,GAAIvB,SAAQK,OAAM6B,UAC/CwJ,IACH1L,EAAS,IAEJiM,EAAGJ,YAEJ,GASMM,CAASd,GACvB3O,KAAKqC,SAAW,EAOlB,MAAME,GACJ,MAAM,IAAI6M,iBAAiBhK,EAAYpF,KAAKoC,OAAQpC,KAAKqC,SAAUrC,KAAKsC,QAASC,IAMnF,MAAMkB,GACJ,OAAOzD,KAAKoC,OAAOsB,OAAS1D,KAAKqC,UAAYrC,KAAKoC,OAAOpC,KAAKqC,UAAUoB,OAASA,EAMnF,WAAWiM,GACT,IAAK,MAAMjM,KAAQiM,EAAY,CAC7B,IAAK1P,KAAKoJ,MAAM3F,GAAO,SACvB,MAAM6B,EAAQtF,KAAKoC,OAAOpC,KAAKqC,UAE/B,OADArC,KAAKqC,WACEiD,GAOX,UAAUjD,GACRrC,KAAKqC,SAAWA,GAIb,MAAM+M,yBAAyBE,MAWpC,aAAY,QAAE/M,EAAO,YAAEyC,EAAW,QAAEX,EAAO,KAAEV,EAAI,WAAEsB,EAAU,MAAEC,EAAK,OAAEC,IACpEkC,MAAM9E,GAENvC,KAAKW,KAAO,mBACZX,KAAKgF,YAAcA,EACnBhF,KAAKqE,QAAUA,EACfrE,KAAK2D,KAAOA,EACZ3D,KAAKiF,WAAaA,EAClBjF,KAAKkF,MAAQA,EACblF,KAAKmF,OAASA,GCnRlB,MAAM,uBAAkB,YAItB,aAAamC,GACX,MAAMjG,EAAQiG,EAAUC,QAAQ,UAChC,GAAIlG,EACF,OAAO,IAAI,eAAU,CAAEe,OAAQkF,EAAUlF,OAAQ+C,OAAQ,CAAE9D,WAI/D,WACE,MAAO,aAET,YACE,OAAOgG,MAAMhG,MAAMyB,MAAM,GAAI,IAI1B,MAAM,kBAAa2C,KAIxB,aAAa6B,GAEX,MAAMnC,EAAS,GAEf,GADAA,EAAOR,KAAO2C,EAAUC,QAAQ,SAC3BpC,EAAOR,KACV,OAEFQ,EAAOxE,KAAO2G,EAAUC,QAAQ,eAAiBD,EAAUiB,MAAM,oBACjE,MAAMR,EAAMC,EAAa,IAAI,UAAK,CAAE5F,OAAQkF,EAAUlF,OAAQ+C,YAgB9D,OAfAmC,EAAUhF,QAAUyF,EAAI/H,KACxBmF,EAAO+C,KAAOZ,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,iBACxDR,EAAIiG,OAAS,EAAK1G,EAAW,CAC3BG,OAAQ,eAAUoB,MAClBiE,cAAc,EACdpF,SAAU,gBAERJ,EAAU8B,MAAM,WAClB9B,EAAUiB,MAAM,gCAElBpD,EAAOuD,MAAQpB,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,4BACpDR,EAAIiG,OAAOtK,QACd4D,EAAUiB,MAAM,oBAElBpD,EAAOoH,YAAcjF,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,2BACxDR,EAAI/H,KAGb,WACE,MAAO,OAET,WACE,OAAO,EAASA,KAAKmF,OAAOxE,KAAKU,QCrD9B,MAAM,0BAAiBoE,KAI5B,aAAa6B,GACX,MAAM1C,EAAS0C,EAAUC,QAAQ,cACjC,IAAK3C,EACH,OAEF,MAAMO,EAAS,CAAEP,UAEjB,GADAO,EAAOqH,SAAWlF,EAAUC,QAAQ,YAC/BpC,EAAOqH,SAMZ,OAFArH,EAAOwK,MAAQrI,EAAUC,QAAQ,eAAiBD,EAAUiB,MAAM,iCAClEpD,EAAOoH,YAAcjF,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,2CACxD,IAAI,kBAAS,CAAEnG,OAAQkF,EAAUlF,OAAQ+C,WAL9CmC,EAAUiE,UAAU3G,EAAOY,OAQ/B,WACE,MAAO,WAET,aACE,OAAO,EAASxF,KAAKmF,OAAOP,OAAOvD,OAErC,eACE,OAAO,EAASrB,KAAKmF,OAAOwK,MAAMtO,QC7B/B,MAAM,wBAAgBoE,KAI3B,aAAa6B,GAEX,MAAMnC,EAAS,GACT4C,EAAMC,EAAa,IAAI,gBAAQ,CAAE5F,OAAQkF,EAAUlF,OAAQ+C,YAEjE,GADAA,EAAOR,KAAO2C,EAAUC,QAAQ,WAC3BpC,EAAOR,KAOZ,OAJAoD,EAAI1B,QAAUqD,EAA8BpC,EAAW,iBAAmBA,EAAUiB,MAAM,wBAC1FpD,EAAOxE,KAAO2G,EAAUC,QAAQ,eAAiBD,EAAUiB,MAAM,wBACjEjB,EAAUhF,QAAUyF,EAAI/H,KACxBmF,EAAOoH,YAAcjF,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,sCACxDR,EAAI/H,KAGb,WACE,MAAO,UAET,WACE,OAAO,EAASA,KAAKmF,OAAOxE,KAAKU,OAGnC,UAAUiF,SACDtG,KAAKqG,QAAQ6C,SAAS5C,IC3B1B,MAAM,kCAAyBb,KAIpC,aAAa6B,EAAW3C,GACtB,MAAMQ,EAAS,CAAER,QACXoD,EAAMC,EAAa,IAAI,0BAAiB,CAAE5F,OAAQkF,EAAUlF,OAAQ+C,YAS1E,OARAA,EAAOxE,KAAO2G,EAAUC,QAAQ,eAAiBD,EAAUiB,MAAM,yBACjEjB,EAAUhF,QAAUyF,EAAI/H,KACxBmF,EAAO2C,OAASR,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,gCAC1DR,EAAI1B,QAAUoD,EAAYnC,IAAcA,EAAUiB,MAAM,gCACxDpD,EAAO+C,KAAOZ,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,4CACxDR,EAAIkB,UAAYR,EAAcnB,GAC9BnC,EAAOuD,MAAQpB,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,yBACzDpD,EAAOoH,YAAcjF,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,uCACxDR,EAAI/H,KAGb,WACE,MAAO,WAET,WACE,OAAO,EAASA,KAAKmF,OAAOxE,KAAKU,OAGnC,UAAUiF,SACDtG,KAAKuK,SAASrB,SAAS5C,SACvBtG,KAAKqG,QAAQ6C,SAAS5C,ICd1B,MAAM,4BAAkBb,KAO3B,aAAa6B,EAAWsI,GAAU,KAAEnM,EAAI,YAAEoM,EAAW,eAAEC,IACrD,MAAM,OAAE3K,GAAWyK,EASnB,IARAzK,EAAOxE,KAAO2G,EAAUC,QAAQ,eAAiBD,EAAUiB,MAAM,mBAAmBqH,EAASnM,MAC7F6D,EAAUhF,QAAUsN,EACpBA,EAAW5H,EAAa4H,GACpBC,GACF/O,OAAOgH,OAAO3C,EAtBtB,SAAqBmC,GACnB,MAAMyI,EAAQzI,EAAUC,QAAQ,KAChC,OAAKwI,EAIE,CAAEA,QAAOjK,YADIwB,EAAUC,QAAQ,eAAiBD,EAAUiB,MAAM,6BAF9D,GAmBmBzC,CAAYwB,IAEpCnC,EAAO+C,KAAOZ,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,YAAY9E,GACpEmM,EAAShE,QAAU,KACN,CAEX,GADAzG,EAAOuD,MAAQpB,EAAUC,QAAQ,KAC7BpC,EAAOuD,MAET,OADAvD,EAAOoH,YAAcjF,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,2BAA2B9E,GACnFmM,EAAS5P,KAElB,MAAMgQ,EAAK,uCAAmBnH,MAAMvB,GACpC,IAAI2I,EACJ,IAAK,MAAOxI,KAAWyI,KAASJ,EAE9B,GADAG,EAAMjI,EAAaP,EAAOH,KAAc4I,IACpCD,EACF,MAGCA,GACH3I,EAAUiB,MAAM,kBAElB0H,EAAI1F,SAAWyF,EACfJ,EAAShE,QAAQzC,KAAK8G,EAAIjQ,OAI9B,cACE,QAASA,KAAKmF,OAAOb,QAEvB,WACE,OAAO,EAAStE,KAAKmF,OAAOxE,KAAKU,OAEnC,kBACE,OAAKrB,KAAKmF,OAAOW,YAGV,EAAS9F,KAAKmF,OAAOW,YAAYzE,OAF/B,KAKX,UAAUiF,GACR,IAAK,MAAM6J,KAAUnQ,KAAK4L,QACpBuE,EAAOjH,iBACFiH,EAAOjH,SAAS5C,KCnE1B,MAAM,0BAAiBb,KAI5B,aAAa6B,GAEX,MAAMnC,EAAS,GAEf,GADAA,EAAOR,KAAO2C,EAAUC,QAAQ,UAC3BpC,EAAOR,KACV,OAEF,IAAI0B,EAAU4D,EAAe3C,GAC7B,IAAKjB,EAAS,CACZ,MAAM1B,EAAO2C,EAAUC,QAAQ,eAAiBD,EAAUiB,MAAM,sBAChElC,EAAU,IAAI,UAAK,CAAEjE,OAAQkF,EAAUlF,OAAQ+C,OAAQ,CAAER,UAEvD2C,EAAU8B,MAAM,MAClB9B,EAAUiB,MAAM,qCAElBlC,EAAQ5C,KAAO,aACf0B,EAAOxE,KAAO2G,EAAUC,QAAQ,eAAiBD,EAAUiB,MAAM,sBACjEpD,EAAO2C,OAASR,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,gCAC1DpD,EAAO9D,MAAQyJ,EAAYxD,IAAcA,EAAUiB,MAAM,uBACzDpD,EAAOoH,YAAcjF,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,oCAC/D,MAAMR,EAAM,IAAI,kBAAS,CAAE3F,OAAQkF,EAAUlF,OAAQ+C,WAErD,OADA6C,EAAaD,GAAK1B,QAAUA,EACrB0B,EAGT,WACE,MAAO,QAET,WACE,OAAO,EAAS/H,KAAKmF,OAAOxE,KAAKU,OAEnC,YACE,OAAO2J,EAAWhL,KAAKmF,OAAO9D,QCrC3B,MAAM,8BAAqBoE,KAIhC,aAAa6B,GACX,MAAM4D,EAAiB5D,EAAUjF,SAC3B8C,EAAS,GACT4C,EAAMC,EAAa,IAAI,sBAAa,CAAE5F,OAAQkF,EAAUlF,OAAQ+C,YAStE,GARAA,EAAOwH,SAAWrF,EAAUC,QAAQ,YAC/BpC,EAAOwH,WACVxH,EAAOiL,MAAQ9I,EAAUC,QAAQ,UAEnCpC,EAAOR,KACLQ,EAAOwH,SAAWrF,EAAUC,QAAQ,UAAW,WAC/CpC,EAAOiL,MAAQ9I,EAAUC,QAAQ,YACjCD,EAAUC,QAAQ,WAAY,UAAW,YACtCpC,EAAOR,KAEV,YADA2C,EAAUiE,UAAUL,GAItB,MAAM,KAAEzH,GAASsE,EACXsI,EAA8B,YAAT5M,EACrB6M,EAAoBD,GAA+B,aAAT5M,EAC1C8M,EAAkBxI,EAAIqI,OAAkB,aAAT3M,EAErC0B,EAAO+C,KAAOZ,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,mCAAmC9E,iBAC3F,MAAMsJ,EAAQrD,EAA8BpC,IAAcA,EAAUiB,MAAM,8BAA8B9E,iBA4BxG,OA3BAsE,EAAI1B,QAAU,CAAC0G,GACfhF,EAAIkB,UAAY,GAEZqH,IACFvD,EAAM5H,OAAO2E,UAAYxC,EAAUC,QAAQ,KACvCwF,EAAM5H,OAAO2E,UACf/B,EAAI1B,QAAQ8C,KAAKO,EAA8BpC,IAExC+I,GACP/I,EAAUiB,MAAM,mCAAmC9E,kBAIvD0B,EAAOuD,MAAQpB,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,sCAAsC9E,iBAE3F6D,EAAU8B,MAAM,OACdmH,GACFpL,EAAOqL,SAAWlJ,EAAUC,QAAQ,KACpCQ,EAAIkB,UAAUE,QAAQV,EAAcnB,IACpCnC,EAAOsL,UAAYnJ,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,8CAE7DjB,EAAUiB,MAAM,oDAIpBpD,EAAOoH,YAAcjF,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,2BAA2B9E,iBAEnFsE,EAAI/H,KAGb,WACE,OAAOA,KAAKmF,OAAOR,KAAKtD,MAE1B,eACE,QAASrB,KAAKmF,OAAOwH,SAEvB,YACE,QAAS3M,KAAKmF,OAAOiL,MAGvB,UAAU9J,GACR,IAAK,MAAM7C,KAAQzD,KAAKqG,cACf5C,EAAKyF,SAAS5C,GAEvB,IAAK,MAAMmG,KAAYzM,KAAKiJ,gBACnBwD,EAASvD,SAAS5C,ICzExB,MAAM,gCAAoBb,KAI/B,aAAa6B,GACX,MAAM3C,EAAO2C,EAAUC,QAAQ,eAC/B,IAAK5C,EACH,OAGF,MAAMQ,EAAS,CAAER,QACjBQ,EAAO+C,KAAOZ,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,mCACxD,MAAM2H,EAAOzH,EAAcnB,GAC3BnC,EAAOuD,MAAQpB,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,4BACzDpD,EAAOoH,YAAcjF,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,kCAC/D,MAAMR,EAAM,IAAI,wBAAY,CAAE3F,OAAQkF,EAAUlF,OAAQ+C,WAExD,OADA6C,EAAaD,GAAKkB,UAAYiH,EACvBnI,EAGT,WACE,MAAO,cAGT,UAAUzB,GACJtG,KAAKqG,gBACArG,KAAKqG,QAAQ6C,SAAS5C,IAE/B,IAAK,MAAMmG,KAAYzM,KAAKiJ,gBACnBwD,EAASvD,SAAS5C,ICjB/B,SAASoK,EAAcpJ,GACrB,MAAM+E,EAAU/E,EAAUC,QAAQ,UAClC,GAAK8E,EAIL,OAHe,oBAAUxD,MAAMvB,EAAW,CAAE+E,aAC1C,oBAAUxD,MAAMvB,EAAW,CAAE+E,aAC7B/E,EAAUiB,MAAM,4BAIb,MAAM,4BAAkB,oBAI7B,aAAajB,EAAW3C,GAAM,QAAEL,EAAU,MAAS,IACjD,MAAMa,EAAS,CAAEb,UAASK,QAC1B,OAAO,oBAAUkE,MAAMvB,EAAW,IAAI,oBAAU,CAAElF,OAAQkF,EAAUlF,OAAQ+C,WAAW,CACrF1B,KAAM,YACNoM,aAAcvL,EACdwL,eAAgB,CACd,CAAC,kBAASjH,OACV,CAAC,wBAAYA,OACb,CAAC6H,GACD,CAACpD,GACD,CAAC,sBAAazE,OACd,CAAC,oBAAUA,OACX,CAAC,oBAAUA,UAKjB,WACE,MAAO,YAGT,UAAUvC,GAER,SADOtG,KAAKuK,SAASrB,SAAS5C,IAE3BtG,KAAKsE,SACNtE,KAAKuK,SAASoG,MAAM5H,GAA4B,YAAjBA,EAAQpI,OACvCX,KAAKuK,SAASoG,MAAM5H,GAA4B,4BAAjBA,EAAQpI,MACvC,CACA,MAAM4B,EAAU,oTAKV8C,EAAgBrF,KAAKmF,OAAOxE,KAAMX,KAAM,kBAAmBuC,EAAS,CACxEG,QAASiL,EAAwB3N,QAGrC,MAAM4Q,EAAkB5Q,KAAKuK,SAASI,OAAO5B,GAA4B,gBAAjBA,EAAQpI,MAChE,IAAK,MAAMkQ,KAAeD,EAAiB,CACzC,MAAMrO,EAAU,oRAIV8C,EAAgBwL,EAAY1L,OAAOxE,KAAMX,KAAM,qBAAsBuC,EAAS,CAClFG,QAASoO,EAAmB9Q,KAAM6Q,KAKtC,GADiB7Q,KAAKuK,SAASsB,KAAK9C,GAA4B,WAAjBA,EAAQpI,MACzC,CACZ,MAAMoQ,EAAmB/Q,KAAKuK,SAASI,OAAO5B,GAA4B,0BAAjBA,EAAQpI,MACjE,IAAK,MAAMqQ,KAASD,EAAkB,CACpC,MAAMxO,EAAU,uEACV8C,EAAgB2L,EAAM7L,OAAOxE,KAAMX,KAAM,0BAA2BuC,GAG5E,MAAM0O,EAAejR,KAAK4L,QAAQjB,OAAOwF,GAA0B,gBAAhBA,EAAO1M,MAC1D,IAAK,MAAMuN,KAASC,EAAc,CAChC,MAAM1O,EAAU,kEACV8C,EAAgB2L,EAAM7L,OAAOR,KAAM3E,KAAM,0BAA2BuC,UAIvE8E,MAAM6B,SAAS5C,GACjBtG,KAAKsE,gBCxFP,UAA0CgC,EAAMlG,GACrD,MAAM8Q,EAAU,IAAIC,IAAIC,EAAchR,GAAGiD,IAAIgO,GAAMA,EAAG1Q,OAChD2Q,EAAWhL,EAAKgL,SAASrQ,IAAIb,EAAEO,OAAS,GACxC4Q,EAASjL,EAAKkL,SAASvQ,IAAIb,EAAEO,OAAS,GAC5C,IAAK,MAAM8Q,IAAO,IAAIH,KAAaC,GAAS,CAC1C,MAAMG,EAAYN,EAAcK,SACzBE,EAAiBD,EAAWR,EAASO,EAAKrR,GACjD,IAAK,MAAMwR,KAAYF,EACrBR,EAAQW,IAAID,EAASjR,MAIzB,SAAUgR,EAAiBD,EAAWI,EAAWL,EAAK9M,GACpD,IAAK,MAAMiN,KAAYF,EAAW,CAChC,MAAM,KAAE/Q,GAASiR,EACjB,GAAIjR,GAAQmR,EAAUjL,IAAIlG,GAAO,CAC/B,MAAM4B,EAAU,kBAAkB5B,uDAA0DgE,EAAKhE,6CAC3F0E,EAAgBuM,EAASzM,OAAOxE,KAAM8Q,EAAK,oBAAqBlP,KAK5E,SAAS6O,EAAchR,GACrB,OAAOA,EAAEwL,QACNjB,OAAO,EAAElH,UAAmB,cAATA,IDiEbsO,CAAgCzL,EAAMtG,QAKnD,SAAS8Q,EAAmBkB,EAAcC,GAExC,OADAD,EAAehK,EAAagK,GACrB,KACL,MAAME,EAAc3E,EAAmByE,EAAazH,SAASpF,OAAO+C,KAAK5E,QACnE6O,EAAeH,EAAapG,QAAQlI,OACxC6J,EAAmBnB,EAAc4F,EAAapG,QAAQ,IAAItI,QVwEzD,SAA8B8O,GACnC,MAAMF,EAAc3E,EAAmB6E,GACjCC,EAAWH,EAAY1F,SAAS,MAAQ,KAAO,KACrD,OAAO0F,EAAcG,EU1EjBC,CAAqBJ,GACjBK,EAAgB,wBAAY1J,MAAM,IAAI,oBAAU,KAAKsJ,oBAC3DI,EAAchI,SAAW,IAAI,uCAAmB,IAChDvC,EAAauK,GAAetJ,UAAYgJ,EAAmBhJ,UAE3D,MAAMuJ,EVoHH,SAAuBC,EAAOC,GACnC,MAAMlN,EAAQiN,EAAM3P,QAAQ6P,UAAUC,UAAUF,GAChD,OAAe,IAAXlN,EACKA,EAEFiN,EAAM/O,OAAS8B,EAAQ,EUzHNqN,CAAcb,EAAapG,QAASpL,GAAgB,gBAAXA,EAAEiD,MACjEuO,EAAapG,QAAQkH,OAAON,EAAgB,EAAG,EAAGD,GAElD,MAAM,MAAE7J,GAAWsJ,EAAa7M,OAC3BuD,EAAMpF,OAAOkJ,SAAS,QACzB9D,EAAMpF,QAAU,KAAK4O,GAGvB,MAAM,SAAE3H,GAAayH,EACfxM,EAAQ+E,EAASyB,QAAQiG,GACzBc,EAAUxI,EAASuI,OAAOtN,EAAO,GAClC+E,EAAS7G,OAEH6G,EAAS7G,SAAW8B,EAC7B+E,EAAS/E,EAAQ,GAAGL,OAAO2E,eAAYjE,EAC7B0E,EAAS/E,GAAOL,OAAOxE,KAAK2C,OAAO0P,SAC7CzI,EAAS/E,GAAOL,OAAOxE,KAAK2C,OAASyP,EAAQ,GAAG5N,OAAOxE,KAAK2C,QAJ5DiH,EAASpF,OAAO+C,KAAOqC,EAASpF,OAAOuD,WAAQ7C,GEnH9C,MAAM,oBAAc,oBASzB,aAAayB,EAAW3C,GAAM,QAAEL,GAAY,IAC1C,MAAMa,EAAS,CAAEb,UAASK,QAE1B,GADAQ,EAAOwK,MAAQrI,EAAUC,QAAQ,SAC5BpC,EAAOwK,MAGZ,OAAO,oBAAU9G,MAAMvB,EAAW,IAAI,YAAM,CAAElF,OAAQkF,EAAUlF,OAAQ+C,WAAW,CACjF1B,KAAM,kBACNqM,eAAgB,CACd,CAAC,kBAASjH,OACV,CAACyE,GACD,CAAC,oBAAUzE,MAAO,CAAE6D,WAAW,IAC/B,CAAC,oBAAU7D,MAAO,CAAEyD,SAAS,OAKnC,WACE,MAAO,mBC5BJ,MAAM,oBAAc7G,KAIzB,aAAa6B,GAEX,MAAMnC,EAAS,GACT4C,EAAMC,EAAa,IAAI,YAAM,CAAE5F,OAAQkF,EAAUlF,OAAQ+C,YAQ/D,OAPA4C,EAAIwC,SAAW,uCAAmB1B,MAAMvB,GACxCnC,EAAO4G,SAAWzE,EAAUC,QAAQ,YACpCQ,EAAI1B,QAAUqD,EAA8BpC,EAAW,oBAAsBA,EAAUiB,MAAM,kCAC7FpD,EAAOxE,KAAO2G,EAAUC,QAAQ,eAAiBD,EAAUiB,MAAM,kCACjER,EAAIuD,QAAU,gBAAQzC,MAAMvB,GACxBnC,EAAO4G,UAAYhE,EAAIuD,SAAShE,EAAUiB,MAAM,2CACpDpD,EAAOoH,YAAcjF,EAAUC,QAAQ,MAAQD,EAAUiB,MAAM,gDACxDR,EAAI/H,KAGb,WACE,MAAO,QAET,WACE,OAAO,EAASA,KAAKmF,OAAOxE,KAAKU,OAEnC,eACE,QAASrB,KAAKmF,OAAO4G,SAGvB,UAAUzF,SACDtG,KAAKqG,QAAQ6C,SAAS5C,IC7B1B,MAAM,8BAAmB,oBAM9B,aAAagB,GAAW,QAAEhD,GAAY,IACpC,MAAMa,EAAS,CAAEb,WAEjB,GADAa,EAAOR,KAAO2C,EAAUC,QAAQ,cAC3BpC,EAAOR,KAGZ,OAAO,oBAAUkE,MAAMvB,EAAW,IAAI,sBAAW,CAAElF,OAAQkF,EAAUlF,OAAQ+C,WAAW,CACtF1B,KAAM,aACNoM,aAAcvL,EACdwL,eAAgB,CACd,CAAC,YAAMjH,UAKb,WACE,MAAO,cCrBJ,MAAM,4BAAkB,oBAM7B,aAAavB,GAAW,QAAEhD,GAAY,IACpC,MAAMa,EAAS,CAAEb,WAEjB,GADAa,EAAOR,KAAO2C,EAAUC,QAAQ,aAC3BpC,EAAOR,KAGZ,OAAO,oBAAUkE,MAAMvB,EAAW,IAAI,oBAAU,CAAElF,OAAQkF,EAAUlF,OAAQ+C,WAAW,CACrF1B,KAAM,YACNqM,eAAgB,CACd,CAAC,oBAAUjH,MAAO,CAAE6D,WAAW,EAAMC,UAAU,IAC/C,CAAC,oBAAU9D,MAAO,CAAEyD,SAAS,OAKnC,WACE,MAAO,YAGT,UAAUhG,GACR,IAAKtG,KAAKsE,SAAWtE,KAAKuK,SAASoG,MAAM5H,GAA4B,YAAjBA,EAAQpI,MAAqB,CAC/E,MAAM4B,EAAU,gTAKV8C,EAAgBrF,KAAKmF,OAAOxE,KAAMX,KAAM,kBAAmBuC,EAAS,CACxEG,QAASiL,EAAwB3N,cAG9BqH,MAAM6B,SAAS5C,ICpCnB,MAAM,6CAA0B,oBAIrC,aAAagB,EAAW2L,GAAU,QAAE3O,EAAU,MAAS,IACrD,MAAMa,EAAS,CAAE8N,YAEjB,GADA9N,EAAOR,KAAO2C,EAAUC,QAAQ,aAC3BpC,EAAOR,KAGZ,OAAO,oBAAUkE,MAAMvB,EAAW,IAAI,qCAAkB,CAAElF,OAAQkF,EAAUlF,OAAQ+C,WAAW,CAC7F1B,KAAM,qBACNoM,aAAcvL,EACdwL,eAAgB,CACd,CAAC,kBAASjH,OACV,CAAC,oBAAUA,MAAO,CAAEyD,SAAS,OAKnC,WACE,MAAO,sBCPX,SAAS4G,EAAc5L,EAAW/B,GAChC,MAAMnD,EAASkF,EAAUlF,OAEzB,SAASmG,EAAMiF,GACblG,EAAUiB,MAAMiF,GAGlB,SAASjG,KAAWmI,GAClB,OAAOpI,EAAUC,WAAWmI,GAY9B,SAASyD,EAAWC,GAClB,MAAMzO,EAAO4C,EAAQ,aACrB,GAAK5C,EAIL,OAHY,YAAMkE,MAAMvB,EAAW3C,EAAMyO,IACvC,oBAAUvK,MAAMvB,EAAW3C,EAAMyO,IACjC7K,EAAM,gCAaV,SAAS8K,IACP,OA5BF,WACE,MAAMJ,EAAW1L,EAAQ,YACzB,GAAK0L,EACL,OAAI3L,EAAU8B,MAAM,aACX,qCAAkBP,MAAMvB,EAAW2L,GAErC,0BAAiBpK,MAAMvB,EAAW2L,GAsBlCA,IACLE,KAXJ,WACE,MAAM7O,EAAUiD,EAAQ,WACxB,GAAKjD,EACL,OAAO,sBAAWuE,MAAMvB,EAAW,CAAEhD,aACnC6O,EAAW,CAAE7O,aACb,oBAAUuE,MAAMvB,EAAW,CAAEhD,aAC7BiE,EAAM,qCAMNjE,IACA,sBAAWuE,MAAMvB,IACjB,UAAKuB,MAAMvB,IACX,gBAAQuB,MAAMvB,IACd,kBAASuB,MAAMvB,IACf,oBAAUuB,MAAMvB,GAsBpB,MAAMgM,EAnBN,WACE,IAAKlR,EAAOsB,OAAQ,MAAO,GAC3B,MAAM4C,EAAO,GACb,OAAa,CACX,MAAM0J,EAAK,uCAAmBnH,MAAMvB,GAC9Bb,EAAM4M,IACZ,IAAK5M,EAAK,CACJuJ,EAAGtM,QAAQ6E,EAAM,6BACrB,MAEFP,EAAavB,GAAK8D,SAAWyF,EAC7B1J,EAAK6C,KAAK1C,GAEZ,MAAM8M,EAAMhM,EAAQ,OAIpB,OAHIhC,EAAQiO,UACVlN,EAAK6C,KAAKoK,GAELjN,EAEGmN,GAEZ,OADInM,EAAUjF,SAAWD,EAAOsB,QAAQ6E,EAAM,uBACvC+K,EASF,SAASzK,EAAM2E,EAAKjI,EAAU,IACnC,MAAM+B,EAAY,IAAI,oBAAUkG,GAIhC,YAHkC,IAAvBjI,EAAQN,aACjBqC,EAAUlF,OAAOzB,KAAO4E,EAAQN,YAE3BiO,EAAc5L,EAAW/B,GCtGlC,SAASmO,EAAK1K,GACZ,OAAOA,EAGT,MAAM2K,EAAY,CAChBC,KAAM5G,GAASA,EAAMzJ,KAAK,IAC1BD,OAAQoQ,EACR/S,KAAM+S,EACN3M,UAAW2M,EACXjQ,KAAMiQ,EACNvJ,QAASuJ,EACTG,SAAUH,EACV5N,YAAa4N,EACbL,WAAYK,EACZI,kBAAmBJ,EACnBK,2BAA4BL,GAGvB,SAASM,EAAMC,GAAON,UAAWO,EAAKP,GAAc,IAGzD,SAAS5M,EAAUoN,GAAK,UAAEC,EAAS,QAAE/P,IAInC,OAHK+P,IACHA,EAAYD,EAAItH,WAAW,KAAOsH,EAAIrR,MAAM,GAAKqR,GAE5CD,EAAGnN,UAAUoN,EAAKC,EAAW/P,GAGtC,SAASiB,EAAMhE,EAAG+S,EAAUX,KAASxD,GACnC,IAAK5O,EACH,MAAO,GAET,MAAMD,EAAQgT,EAAQ/S,EAAED,SAAU6O,GAClC,OAAOgE,EAAGN,KAAK,CAACM,EAAG5Q,OAAOhC,EAAEgC,QAASjC,IAGvC,SAASiT,EAAgBhT,EAAG+C,GAC1B,OAAOiB,EAAMhE,EAAGyF,EAAW,CAAE1C,YAG/B,SAASkQ,EAAWjT,EAAG0H,GACrB,OAAO1D,EAAMhE,EAAG4S,EAAGvT,KAAMqI,GAG3B,SAASwL,EAAUC,GACjB,GAAIA,EAAGjO,OAASiO,EAAGtK,QACjB,OAAO+J,EAAGN,KAAK,CACbtO,EAAMmP,EAAGtP,OAAOR,KAAMuP,EAAG/J,SACzB7E,EAAMmP,EAAGtP,OAAO+C,SACbuM,EAAGvN,QAAQ7D,IAAII,GAClB6B,EAAMmP,EAAGtP,OAAOuD,SAGpB,MAAMyD,EAAasI,EAAGtP,OAAOsF,QAAUgK,EAAGtP,OAAOR,KAC3C8F,EAASgK,EAAGtP,OAAOsF,OAAS,CAChCgK,EAAGtP,OAAOsF,OAAOpJ,MACjB6S,EAAG5Q,OAAOmR,EAAGtP,OAAOR,KAAKrB,SACvB,GACEoR,EAAM3N,EAAUmN,EAAGN,KAAK,IACzBnJ,EACHgK,EAAGtP,OAAOR,KAAKtD,MACfiE,EAAMmP,EAAGtP,OAAOuF,WACd,CAAE0J,UAAWK,EAAGpO,QAAShC,QAASoQ,IACtC,OAAOP,EAAGN,KAAK,CAACM,EAAG5Q,OAAO6I,EAAW7I,QAASoR,IAEhD,SAASjR,EAAKgR,GACZ,OAAOP,EAAGN,KAAK,CACbe,EAAoBF,EAAGlK,UACvBiK,EAAUC,GACVnP,EAAMmP,EAAGtP,OAAO8B,UAChB3B,EAAMmP,EAAGtP,OAAO2E,aAGpB,SAAS8K,EAASnO,GAChB,OAAKA,EAGEyN,EAAGN,KAAK,CACbtO,EAAMmB,EAAItB,OAAO2C,WACdrB,EAAIsE,WAAW1H,IAAI/B,GAAKgE,EAAMhE,MAJ1B,GAOX,SAASmL,EAASzD,GAChB,OAAOkL,EAAGN,KAAK,CACbe,EAAoB3L,EAAIuB,UACxBjF,EAAM0D,EAAI7D,OAAOgG,UACjB+I,EAAGzQ,KAAKA,EAAKuF,EAAI3C,UACjBf,EAAM0D,EAAI7D,OAAOiG,UACjBmJ,EAAWvL,EAAI7D,OAAOxE,KAAM,CAAEoN,KAAM/E,IACpC4L,EAAS5L,EAAIsC,SACbhG,EAAM0D,EAAI7D,OAAO2E,aAGrB,SAAS+K,EAA4BrH,GACnC,OAAO0G,EAAGN,KAAK,CACbtO,EAAMkI,EAAIrI,OAAO9D,OACjBiE,EAAMkI,EAAIrI,OAAO2E,aASrB,SAASgL,EAAYL,GACnB,MAAM,QAAE3L,GAAY2L,EAAG7L,OACvB,OAAOsL,EAAGN,KAAK,CACbM,EAAG5Q,OAAOmR,EAAGtP,OAAOxE,KAAK2C,QACzB4Q,EAAGJ,kBAAkBI,EAAGN,KAAK,CAC3BM,EAAGH,2BAA2BU,EAAG9T,MACjC2E,EAAMmP,EAAG7L,OAAOzD,OAAO2C,QACvBwM,EAAgBG,EAAG7L,OAAOzD,OAAO8C,cAAewM,GAChDnP,EAAMmP,EAAG7L,OAAOzD,OAAO+C,SACnBuM,EAAG7L,OAAOT,KACZsM,EAAG7L,OAAOT,KAAK9E,IACD,oBAAZyF,EAAgCiM,GAjB1C,SAAoBA,EAAI1Q,GACtB,OAAO6P,EAAGN,KAAK,CACbU,EAAgBS,EAAG5P,OAAO9D,MAAOgD,GACjCiB,EAAMyP,EAAG5P,OAAO2E,aAc4B8C,CAAWmI,EAAIN,GACrD3L,GAAWA,EAAQkM,SAAS,SAAWH,EACvCpI,GAJiB,GAMrBnH,EAAMmP,EAAG7L,OAAOzD,OAAOuD,UAEzBpD,EAAMmP,EAAGtP,OAAO2E,aAGpB,SAAS6K,EAAoBM,GAC3B,OAAKA,EAAKvR,OACHwQ,EAAGN,KAAK,CACbtO,EAAM2P,EAAK9P,OAAO+C,SACf+M,EAAK5R,IAAIyR,GACZxP,EAAM2P,EAAK9P,OAAOuD,SAJK,GA0D3B,SAASwM,EAAUT,GACjB,OAAOP,EAAGb,WAAWa,EAAGN,KAAK,CAC3Be,EAAoBF,EAAGlK,UACvBjF,EAAMmP,EAAGtP,OAAO8N,UAChB3N,EAAMmP,EAAGtP,OAAOb,SAChBgB,EAAMmP,EAAGtP,OAAOR,MAChBW,EAAMmP,EAAGtP,OAAOwK,OAChB4E,EAAWE,EAAGtP,OAAOxE,KAAM,CAAEoN,KAAM0G,KAlBlBU,EAmBLV,EAlBTU,EAAIhQ,OAAOW,YAGToO,EAAGN,KAAK,CACbtO,EAAM6P,EAAIhQ,OAAO4K,OACjBmE,EAAG5Q,OAAO6R,EAAIhQ,OAAOW,YAAYxC,QACjC4Q,EAAGpO,YAAYiB,EAAUoO,EAAIhQ,OAAOW,YAAYzE,MAAO,CAAEgD,QAAS8Q,OAL3D,IAkBP7P,EAAMmP,EAAGtP,OAAO+C,MAChBkN,EAAQX,EAAG7I,QAAS6I,GACpBnP,EAAMmP,EAAGtP,OAAOuD,OAChBpD,EAAMmP,EAAGtP,OAAOoH,eACd,CAAEwB,KAAM0G,IAxBd,IAAqBU,EAoGrB,SAASE,EAAcZ,EAAIhQ,GACzB,OAAOyP,EAAGb,WAAWa,EAAGN,KAAK,CAC3Be,EAAoBF,EAAGlK,UACvBjF,EAAMmP,EAAGtP,OAAOwH,UAChBrH,EAAMmP,EAAGtP,OAAOiL,OAChB9K,EAAMmP,EAAGtP,OAAOR,KAAMuP,EAAG/J,SACzB7E,EAAMmP,EAAGtP,OAAO+C,MAChBgM,EAAGN,KAAKa,EAAGpO,QAAQhD,IAAII,IACvB6B,EAAMmP,EAAGtP,OAAOuD,OAChBpD,EAAMmP,EAAGtP,OAAOqL,UAChB0D,EAAGN,KAAKa,EAAGxL,UAAU5F,IAAIoJ,IACzBnH,EAAMmP,EAAGtP,OAAOsL,WAChBnL,EAAMmP,EAAGtP,OAAOoH,eACd,CAAEwB,KAAM0G,EAAIhQ,WA3QlByP,EAAKpT,OAAOgH,OAAO,GAAI6L,EAAWO,GAiRlC,MAAMoB,EAAQ,CACZC,UAAWL,EACX,kBAAmBA,EACnBM,UAAWN,EACXO,UAlKF,SAAmBhB,EAAIhQ,GACrB,MAAMiR,EAAOjB,EAAGpO,QAAU,CACxB6N,EAAGzQ,KAAKA,EAAKgR,EAAGpO,UAChBkO,EAAWE,EAAGtP,OAAOxE,KAAM,CAAEoN,KAAM0G,EAAIhQ,WACvCa,EAAMmP,EAAGtP,OAAO+C,MAChBgM,EAAGN,KAAKa,EAAGxL,UAAU5F,IAAIoJ,IACzBnH,EAAMmP,EAAGtP,OAAOuD,QACd,GACJ,OAAOwL,EAAGb,WAAWa,EAAGN,KAAK,CAC3Be,EAAoBF,EAAGlK,UACvBkK,EAAGtP,OAAOxE,KAAO2E,EAAMmP,EAAGtP,OAAOkH,SAAW/G,EAAMmP,EAAGtP,OAAOkH,QAAS6H,EAAGL,SAAU,CAAE9F,KAAM0G,EAAIhQ,cAC3FiR,EACHpQ,EAAMmP,EAAGtP,OAAOoH,eACd,CAAEwB,KAAM0G,EAAIhQ,YAsJhBkR,UAnJF,SAAmBlB,EAAIhQ,GACrB,OAAOyP,EAAGb,WAAWa,EAAGN,KAAK,CAC3Be,EAAoBF,EAAGlK,UACvBjF,EAAMmP,EAAGtP,OAAOkH,SAChB/G,EAAMmP,EAAGtP,OAAOwH,UAChBrH,EAAMmP,EAAGtP,OAAOR,MAChBuP,EAAGzQ,KAAKA,EAAKgR,EAAGpO,UAChBkO,EAAWE,EAAGtP,OAAOxE,KAAM,CAAEoN,KAAM0G,EAAIhQ,WACvCa,EAAMmP,EAAGtP,OAAOoH,eACd,CAAEwB,KAAM0G,EAAIhQ,YA2IhBoM,YAxIF,SAAqB4D,EAAIhQ,GACvB,OAAOyP,EAAGb,WAAWa,EAAGN,KAAK,CAC3Be,EAAoBF,EAAGlK,UACvBjF,EAAMmP,EAAGtP,OAAOR,KAAMuP,EAAGL,SAAU,CAAE9F,KAAM0G,EAAIhQ,WAC/Ca,EAAMmP,EAAGtP,OAAO+C,MAChBgM,EAAGN,KAAKa,EAAGxL,UAAU5F,IAAIoJ,IACzBnH,EAAMmP,EAAGtP,OAAOuD,OAChBpD,EAAMmP,EAAGtP,OAAOoH,eACd,CAAEwB,KAAM0G,EAAIhQ,YAiIhBuC,WAAYkO,EACZpJ,MApGF,SAAe2I,EAAIhQ,GACjB,OAAOyP,EAAGb,WAAWa,EAAGN,KAAK,CAC3Be,EAAoBF,EAAGlK,UACvBjF,EAAMmP,EAAGtP,OAAO4G,UAChBmI,EAAGzQ,KAAKA,EAAKgR,EAAGpO,UAChBkO,EAAWE,EAAGtP,OAAOxE,KAAM,CAAEoN,KAAM0G,EAAIhQ,WACvCmQ,EAASH,EAAGnJ,SACZhG,EAAMmP,EAAGtP,OAAOoH,eACd,CAAEwB,KAAM0G,EAAIhQ,YA6FhBmR,MA3FF,SAAgBnB,EAAIhQ,GAClB,OAAOyP,EAAGb,WAAWa,EAAGN,KAAK,CAC3Be,EAAoBF,EAAGlK,UACvBjF,EAAMmP,EAAGtP,OAAOR,MAChBuP,EAAGzQ,KAAKA,EAAKgR,EAAGpO,UAChBkO,EAAWE,EAAGtP,OAAOxE,KAAM,CAAEoN,KAAM0G,EAAIhQ,WACvCa,EAAMmP,EAAGtP,OAAO2C,QAChBxC,EAAMmP,EAAGtP,OAAO9D,OAChBiE,EAAMmP,EAAGtP,OAAOoH,eACd,CAAEwB,KAAM0G,EAAIhQ,YAmFhBmG,QAjFF,SAAiB6J,GACf,OAAOP,EAAGb,WAAWa,EAAGN,KAAK,CAC3Be,EAAoBF,EAAGlK,UACvBjF,EAAMmP,EAAGtP,OAAOR,MAChBuP,EAAGzQ,KAAKA,EAAKgR,EAAGpO,UAChBkO,EAAWE,EAAGtP,OAAOxE,KAAM,CAAEoN,KAAM0G,IACnCnP,EAAMmP,EAAGtP,OAAOoH,eACd,CAAEwB,KAAM0G,KA2EZjI,SAzEF,SAAkBiI,GAChB,OAAOP,EAAGb,WAAWa,EAAGN,KAAK,CAC3Be,EAAoBF,EAAGlK,UACvB+J,EAAgBG,EAAGtP,OAAOP,OAAQ6P,GAClCnP,EAAMmP,EAAGtP,OAAOqH,UAChB8H,EAAgBG,EAAGtP,OAAOwK,MAAO8E,GACjCnP,EAAMmP,EAAGtP,OAAOoH,eACd,CAAEwB,KAAM0G,KAmEZxB,SAjEF,SAAkBwB,GAChB,OAAOP,EAAGb,WAAWa,EAAGN,KAAK,CAC3Be,EAAoBF,EAAGlK,UACvBjF,EAAMmP,EAAGtP,OAAOR,MAChB4P,EAAWE,EAAGtP,OAAOxE,KAAM,CAAEoN,KAAM0G,IACnCnP,EAAMmP,EAAGtP,OAAO2C,QAChBoM,EAAGzQ,KAAKA,EAAKgR,EAAGpO,UAChBf,EAAMmP,EAAGtP,OAAO+C,SACbuM,EAAGxL,UAAU5F,IAAIoJ,GACpBnH,EAAMmP,EAAGtP,OAAOuD,OAChBpD,EAAMmP,EAAGtP,OAAOoH,eACd,CAAEwB,KAAM0G,KAuDZoB,KArDF,SAAepB,GACb,OAAOP,EAAGb,WAAWa,EAAGN,KAAK,CAC3Be,EAAoBF,EAAGlK,UACvBjF,EAAMmP,EAAGtP,OAAOR,MAChB4P,EAAWE,EAAGtP,OAAOxE,KAAM,CAAEoN,KAAM0G,IACnCnP,EAAMmP,EAAGtP,OAAO+C,MAChBkN,EAAQX,EAAGzG,OAAQyG,GACnBnP,EAAMmP,EAAGtP,OAAOuD,OAChBpD,EAAMmP,EAAGtP,OAAOoH,eACd,CAAEwB,KAAM0G,KA6CZ,aA3CF,SAAoBqB,EAAGrR,GACrB,OAAOyP,EAAGN,KAAK,CACbM,EAAG5Q,OAAOwS,EAAE3Q,OAAO9D,MAAMiC,QACzB4Q,EAAGb,WACDa,EAAGN,KAAK,CAAC,IAAKM,EAAGvT,KAAKmV,EAAEzU,MAAO,CAAE0M,KAAM+H,EAAGrR,WAAW,MACrD,CAAEsJ,KAAM+H,EAAGrR,WAEba,EAAMwQ,EAAE3Q,OAAO2E,cAqCjBiM,SAAUV,EACVW,QAASX,EACTY,QAASZ,EACT,qBAAsBH,EACtB3B,IAvBF,SAAakB,GACX,OAAOP,EAAG5Q,OAAOmR,EAAGnR,UA+BtB,SAAS8R,EAAQc,EAAQzR,GACvB,IAAKyR,EAAQ,OACb,MAAMC,EAAUD,EAAO7S,IAAI+S,GAT7B,SAAkB3B,EAAIhQ,GAEpB,IADmB6Q,EAAMb,EAAGhR,MAE1B,MAAM,IAAI6L,MAAM,SAASmF,EAAGhR,wBAE9B,OAAO6R,EAAMb,EAAGhR,MAAMgR,EAAIhQ,GAIU4R,CAASD,EAAO3R,IACpD,OAAOyP,EAAGN,KAAKuC,GAEjB,OAAOf,EAAQnB,GCnUjB,SAASqC,EAAYC,EAAK7P,GACxB,MAAMrD,EAAM,IAAIwE,IACV2E,EAAW+J,EAAI5L,OAAOlE,GAAoB,aAAbA,EAAIhD,MACvC,IAAK,MAAM+S,KAAWhK,EAAU,CAC9B,MAAMmD,EAAQjJ,EAAOzF,IAAIuV,EAAQhK,UACjC,IAAKmD,EACH,SAEF,MAAM8C,EAAQpP,EAAIpC,IAAIuV,EAAQ5R,QAC1B6N,EACFA,EAAMtJ,KAAKwG,GAEXtM,EAAIyD,IAAI0P,EAAQ5R,OAAQ,CAAC+K,IAG7B,OAAOtM,EAkDT,SAAUoT,EAAiBxC,GACzB,MAAM3N,EA7CR,SAA0BiQ,GACxB,MAAM7P,EAAS,IAAImB,IACb6O,EAAa,IAAIvF,IACjBG,EAAW,IAAIzJ,IACrB,IAAK,MAAMpB,KAAO8P,EAChB,GAAI9P,EAAInC,QAAR,CACE,MAAMmO,EAAQnB,EAASrQ,IAAIwF,EAAI9F,MAC3B8R,EACFA,EAAMtJ,KAAK1C,GAEX6K,EAASxK,IAAIL,EAAI9F,KAAM,CAAC8F,SAIvBA,EAAI9F,OAGJ+F,EAAOG,IAAIJ,EAAI9F,MAGlB+V,EAAW7E,IAAIpL,GAFfC,EAAOI,IAAIL,EAAI9F,KAAM8F,IAKzB,MAAO,CACL8P,MACA7P,SACA4K,WACAoF,aACAlF,SAAU8E,EAAYC,EAAK7P,GAC3BE,MAAO,CACLD,0BAA2B,IAAIgQ,QAC/BlL,gCAAiC,IAAIkL,UAc5BC,CAAiB3C,GAC9B,IAAK,MAAMxN,KAAOH,EAAKiQ,IACjB9P,EAAIyC,iBACCzC,EAAIyC,SAAS5C,UAZ1B,WAA+B,OAAEI,EAAM,WAAEgQ,IACvC,IAAK,MAAMG,KAAOH,EAAY,CAC5B,MAAM,KAAE/V,GAASkW,EACXtU,EAAU,aAAa5B,eAAkB+F,EAAOzF,IAAIN,GAAM8C,+BAC1D,EAAMoT,EAAI1R,OAAOxE,KAAMkW,EAAK,eAAgBtU,IAW7CuU,CAAqBxQ,GAcvB,SAAS4C,EAAS+K,GACvB,MAAO,IAAIwC,GAXIhE,EAWqBwB,EAVhCxB,EAAMsE,KACDtE,EAAMsE,OAER,GAAGvI,UAAUiE,MAJtB,IAAiBA","file":"webidl2.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"WebIDL2\"] = factory();\n\telse\n\t\troot[\"WebIDL2\"] = factory();\n})(this, function() {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 0);\n","/**\n * @param {string} text\n */\nfunction lastLine(text) {\n  const splitted = text.split(\"\\n\");\n  return splitted[splitted.length - 1];\n}\n\nfunction appendIfExist(base, target) {\n  let result = base;\n  if (target) {\n    result += ` ${target}`;\n  }\n  return result;\n}\n\nfunction contextAsText(node) {\n  const hierarchy = [node];\n  while (node && node.parent) {\n    const { parent } = node;\n    hierarchy.unshift(parent);\n    node = parent;\n  }\n  return hierarchy.map(n => appendIfExist(n.type, n.name)).join(\" -> \");\n}\n\n/**\n * @typedef {object} WebIDL2ErrorOptions\n * @property {\"error\" | \"warning\"} [level]\n * @property {Function} [autofix]\n *\n * @param {string} message error message\n * @param {\"Syntax\" | \"Validation\"} kind error type\n * @param {WebIDL2ErrorOptions} [options]\n */\nfunction error(source, position, current, message, kind, { level = \"error\", autofix, ruleName } = {}) {\n  /**\n   * @param {number} count\n   */\n  function sliceTokens(count) {\n    return count > 0 ?\n      source.slice(position, position + count) :\n      source.slice(Math.max(position + count, 0), position);\n  }\n\n  function tokensToText(inputs, { precedes } = {}) {\n    const text = inputs.map(t => t.trivia + t.value).join(\"\");\n    const nextToken = source[position];\n    if (nextToken.type === \"eof\") {\n      return text;\n    }\n    if (precedes) {\n      return text + nextToken.trivia;\n    }\n    return text.slice(nextToken.trivia.length);\n  }\n\n  const maxTokens = 5; // arbitrary but works well enough\n  const line =\n    source[position].type !== \"eof\" ? source[position].line :\n    source.length > 1 ? source[position - 1].line :\n    1;\n\n  const precedingLastLine = lastLine(\n    tokensToText(sliceTokens(-maxTokens), { precedes: true })\n  );\n\n  const subsequentTokens = sliceTokens(maxTokens);\n  const subsequentText = tokensToText(subsequentTokens);\n  const subsequentFirstLine = subsequentText.split(\"\\n\")[0];\n\n  const spaced = \" \".repeat(precedingLastLine.length) + \"^\";\n  const sourceContext = precedingLastLine + subsequentFirstLine + \"\\n\" + spaced;\n\n  const contextType = kind === \"Syntax\" ? \"since\" : \"inside\";\n  const inSourceName = source.name ? ` in ${source.name}` : \"\";\n  const grammaticalContext = (current && current.name) ? `, ${contextType} \\`${current.partial ? \"partial \" : \"\"}${contextAsText(current)}\\`` : \"\";\n  const context = `${kind} error at line ${line}${inSourceName}${grammaticalContext}:\\n${sourceContext}`;\n  return {\n    message: `${context} ${message}`,\n    bareMessage: message,\n    context,\n    line,\n    sourceName: source.name,\n    level,\n    ruleName,\n    autofix,\n    input: subsequentText,\n    tokens: subsequentTokens\n  };\n}\n\n/**\n * @param {string} message error message\n */\nexport function syntaxError(source, position, current, message) {\n  return error(source, position, current, message, \"Syntax\");\n}\n\n/**\n * @param {string} message error message\n * @param {WebIDL2ErrorOptions} [options]\n */\nexport function validationError(token, current, ruleName, message, options = {}) {\n  options.ruleName = ruleName;\n  return error(current.source, token.index, current, message, \"Validation\", options);\n}\n","// @ts-check\n\nexport class Base {\n  /**\n   * @param {object} initializer\n   * @param {Base[\"source\"]} initializer.source\n   * @param {Base[\"tokens\"]} initializer.tokens\n   */\n  constructor({ source, tokens }) {\n    Object.defineProperties(this, {\n      source: { value: source },\n      tokens: { value: tokens, writable: true },\n      parent: { value: null, writable: true },\n      this: { value: this } // useful when escaping from proxy\n    });\n  }\n\n  toJSON() {\n    const json = { type: undefined, name: undefined, inheritance: undefined };\n    let proto = this;\n    while (proto !== Object.prototype) {\n      const descMap = Object.getOwnPropertyDescriptors(proto);\n      for (const [key, value] of Object.entries(descMap)) {\n        if (value.enumerable || value.get) {\n          // @ts-ignore - allow indexing here\n          json[key] = this[key];\n        }\n      }\n      proto = Object.getPrototypeOf(proto);\n    }\n    return json;\n  }\n}\n","// @ts-check\n\n/**\n * @typedef {import(\"../productions/dictionary.js\").Dictionary} Dictionary\n *\n * @param {*} idlType\n * @param {import(\"../validator.js\").Definitions} defs\n * @param {object} [options]\n * @param {boolean} [options.useNullableInner] use when the input idlType is nullable and you want to use its inner type\n * @return {{ reference: *, dictionary: Dictionary }} the type reference that ultimately includes dictionary.\n */\nexport function idlTypeIncludesDictionary(idlType, defs, { useNullableInner } = {}) {\n  if (!idlType.union) {\n    const def = defs.unique.get(idlType.idlType);\n    if (!def) {\n      return;\n    }\n    if (def.type === \"typedef\") {\n      const { typedefIncludesDictionary } = defs.cache;\n      if (typedefIncludesDictionary.has(def)) {\n        // Note that this also halts when it met indeterminate state\n        // to prevent infinite recursion\n        return typedefIncludesDictionary.get(def);\n      }\n      defs.cache.typedefIncludesDictionary.set(def, undefined); // indeterminate state\n      const result = idlTypeIncludesDictionary(def.idlType, defs);\n      defs.cache.typedefIncludesDictionary.set(def, result);\n      if (result) {\n        return {\n          reference: idlType,\n          dictionary: result.dictionary\n        };\n      }\n    }\n    if (def.type === \"dictionary\" && (useNullableInner || !idlType.nullable)) {\n      return {\n        reference: idlType,\n        dictionary: def\n      };\n    }\n  }\n  for (const subtype of idlType.subtype) {\n    const result = idlTypeIncludesDictionary(subtype, defs);\n    if (result) {\n      if (subtype.union) {\n        return result;\n      }\n      return {\n        reference: subtype,\n        dictionary: result.dictionary\n      };\n    }\n  }\n}\n\n/**\n * @param {*} dict dictionary type\n * @param {import(\"../validator.js\").Definitions} defs\n * @return {boolean}\n */\nexport function dictionaryIncludesRequiredField(dict, defs) {\n  if (defs.cache.dictionaryIncludesRequiredField.has(dict)) {\n    return defs.cache.dictionaryIncludesRequiredField.get(dict);\n  }\n  defs.cache.dictionaryIncludesRequiredField.set(dict, undefined); // indeterminate\n  if (dict.inheritance) {\n    const superdict = defs.unique.get(dict.inheritance);\n    if (!superdict) {\n      return true;\n    }\n    if (dictionaryIncludesRequiredField(superdict, defs)) {\n      return true;\n    }\n  }\n  const result = dict.members.some(field => field.required);\n  defs.cache.dictionaryIncludesRequiredField.set(dict, result);\n  return result;\n}\n","// @ts-check\n\nexport class ArrayBase extends Array {\n  constructor({ source, tokens }) {\n    super();\n    Object.defineProperties(this, {\n      source: { value: source },\n      tokens: { value: tokens },\n      parent: { value: null, writable: true }\n    });\n  }\n}\n","// @ts-check\n\nimport { Base } from \"./base.js\";\nimport { unescape } from \"./helpers.js\";\n\nexport class Token extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   * @param {string} type\n   */\n  static parser(tokeniser, type) {\n    return () => {\n      const value = tokeniser.consume(type);\n      if (value) {\n        return new Token({ source: tokeniser.source, tokens: { value } });\n      }\n    };\n  }\n\n  get value() {\n    return unescape(this.tokens.value.value);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { ArrayBase } from \"./array-base.js\";\nimport { Token } from \"./token.js\";\nimport { list, argument_list, autoParenter, unescape } from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} tokenName\n */\nfunction tokens(tokeniser, tokenName) {\n  return list(tokeniser, {\n    parser: Token.parser(tokeniser, tokenName),\n    listName: tokenName + \" list\"\n  });\n}\n\nconst extAttrValueSyntax = [\"identifier\", \"decimal\", \"integer\", \"string\"];\n\nconst shouldBeLegacyPrefixed = [\n  \"NoInterfaceObject\",\n  \"LenientSetter\",\n  \"LenientThis\",\n  \"TreatNonObjectAsNull\",\n  \"Unforgeable\",\n];\n\nconst renamedLegacies = new Map([\n  ...shouldBeLegacyPrefixed.map(name => [name, `Legacy${name}`]),\n  [\"NamedConstructor\", \"LegacyFactoryFunction\"],\n  [\"OverrideBuiltins\", \"LegacyOverrideBuiltIns\"],\n  [\"TreatNullAs\", \"LegacyNullToEmptyString\"],\n]);\n\n/**\n * This will allow a set of extended attribute values to be parsed.\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nfunction extAttrListItems(tokeniser) {\n  for (const syntax of extAttrValueSyntax) {\n    const toks = tokens(tokeniser, syntax);\n    if (toks.length) {\n      return toks;\n    }\n  }\n  tokeniser.error(`Expected identifiers, strings, decimals, or integers but none found`);\n}\n\n\nclass ExtendedAttributeParameters extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = { assign: tokeniser.consume(\"=\") };\n    const ret = autoParenter(new ExtendedAttributeParameters({ source: tokeniser.source, tokens }));\n    if (tokens.assign) {\n      tokens.secondaryName = tokeniser.consume(...extAttrValueSyntax);\n    }\n    tokens.open = tokeniser.consume(\"(\");\n    if (tokens.open) {\n      ret.list = ret.rhsIsList ?\n        // [Exposed=(Window,Worker)]\n        extAttrListItems(tokeniser) :\n        // [LegacyFactoryFunction=Audio(DOMString src)] or [Constructor(DOMString str)]\n        argument_list(tokeniser);\n      tokens.close = tokeniser.consume(\")\") || tokeniser.error(\"Unexpected token in extended attribute argument list\");\n    } else if (ret.hasRhs && !tokens.secondaryName) {\n      tokeniser.error(\"No right hand side to extended attribute assignment\");\n    }\n    return ret.this;\n  }\n\n  get rhsIsList() {\n    return this.tokens.assign && !this.tokens.secondaryName;\n  }\n\n  get rhsType() {\n    if (this.rhsIsList) {\n      return this.list[0].tokens.value.type + \"-list\";\n    }\n    if (this.tokens.secondaryName) {\n      return this.tokens.secondaryName.type;\n    }\n    return null;\n  }\n}\n\nexport class SimpleExtendedAttribute extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const name = tokeniser.consume(\"identifier\");\n    if (name) {\n      return new SimpleExtendedAttribute({\n        source: tokeniser.source,\n        tokens: { name },\n        params: ExtendedAttributeParameters.parse(tokeniser)\n      });\n    }\n  }\n\n  constructor({ source, tokens, params }) {\n    super({ source, tokens });\n    params.parent = this;\n    Object.defineProperty(this, \"params\", { value: params });\n  }\n\n  get type() {\n    return \"extended-attribute\";\n  }\n  get name() {\n    return this.tokens.name.value;\n  }\n  get rhs() {\n    const { rhsType: type, tokens, list } = this.params;\n    if (!type) {\n      return null;\n    }\n    const value = this.params.rhsIsList ? list : unescape(tokens.secondaryName.value);\n    return { type, value };\n  }\n  get arguments() {\n    const { rhsIsList, list } = this.params;\n    if (!list || rhsIsList) {\n      return [];\n    }\n    return list;\n  }\n\n  *validate(defs) {\n    const { name } = this;\n    if (name === \"LegacyNoInterfaceObject\") {\n      const message = `\\`[LegacyNoInterfaceObject]\\` extended attribute is an \\\nundesirable feature that may be removed from Web IDL in the future. Refer to the \\\n[relevant upstream PR](https://github.com/heycam/webidl/pull/609) for more \\\ninformation.`;\n      yield validationError(this.tokens.name, this, \"no-nointerfaceobject\", message, { level: \"warning\" });\n    } else if (renamedLegacies.has(name)) {\n      const message = `\\`[${name}]\\` extended attribute is a legacy feature \\\nthat is now renamed to \\`[${renamedLegacies.get(name)}]\\`. Refer to the \\\n[relevant upstream PR](https://github.com/heycam/webidl/pull/870) for more \\\ninformation.`;\n      yield validationError(this.tokens.name, this, \"renamed-legacy\", message, {\n        level: \"warning\",\n        autofix: renameLegacyExtendedAttribute(this)\n      });\n    }\n    for (const arg of this.arguments) {\n      yield* arg.validate(defs);\n    }\n  }\n}\n\n/**\n * @param {SimpleExtendedAttribute} extAttr\n */\nfunction renameLegacyExtendedAttribute(extAttr) {\n  return () => {\n    const { name } = extAttr;\n    extAttr.tokens.name.value = renamedLegacies.get(name);\n    if (name === \"TreatNullAs\") {\n      extAttr.params.tokens = {};\n    }\n  };\n}\n\n// Note: we parse something simpler than the official syntax. It's all that ever\n// seems to be used\nexport class ExtendedAttributes extends ArrayBase {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = {};\n    tokens.open = tokeniser.consume(\"[\");\n    if (!tokens.open) return new ExtendedAttributes({});\n    const ret = new ExtendedAttributes({ source: tokeniser.source, tokens });\n    ret.push(...list(tokeniser, {\n      parser: SimpleExtendedAttribute.parse,\n      listName: \"extended attribute\"\n    }));\n    tokens.close = tokeniser.consume(\"]\") || tokeniser.error(\"Unexpected closing token of extended attribute\");\n    if (!ret.length) {\n      tokeniser.error(\"Found an empty extended attribute\");\n    }\n    if (tokeniser.probe(\"[\")) {\n      tokeniser.error(\"Illegal double extended attribute lists, consider merging them\");\n    }\n    return ret;\n  }\n\n  *validate(defs) {\n    for (const extAttr of this) {\n      yield* extAttr.validate(defs);\n    }\n  }\n}\n","import { Base } from \"./base.js\";\nimport { unescape, type_with_extended_attributes, return_type, primitive_type, autoParenter } from \"./helpers.js\";\nimport { stringTypes, typeNameKeywords } from \"../tokeniser.js\";\nimport { validationError } from \"../error.js\";\nimport { idlTypeIncludesDictionary } from \"../validators/helpers.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nfunction generic_type(tokeniser, typeName) {\n  const base = tokeniser.consume(\"FrozenArray\", \"ObservableArray\", \"Promise\", \"sequence\", \"record\");\n  if (!base) {\n    return;\n  }\n  const ret = autoParenter(new Type({ source: tokeniser.source, tokens: { base } }));\n  ret.tokens.open = tokeniser.consume(\"<\") || tokeniser.error(`No opening bracket after ${base.type}`);\n  switch (base.type) {\n    case \"Promise\": {\n      if (tokeniser.probe(\"[\")) tokeniser.error(\"Promise type cannot have extended attribute\");\n      const subtype = return_type(tokeniser, typeName) || tokeniser.error(\"Missing Promise subtype\");\n      ret.subtype.push(subtype);\n      break;\n    }\n    case \"sequence\":\n    case \"FrozenArray\":\n    case \"ObservableArray\": {\n      const subtype = type_with_extended_attributes(tokeniser, typeName) || tokeniser.error(`Missing ${base.type} subtype`);\n      ret.subtype.push(subtype);\n      break;\n    }\n    case \"record\": {\n      if (tokeniser.probe(\"[\")) tokeniser.error(\"Record key cannot have extended attribute\");\n      const keyType = tokeniser.consume(...stringTypes) || tokeniser.error(`Record key must be one of: ${stringTypes.join(\", \")}`);\n      const keyIdlType = new Type({ source: tokeniser.source, tokens: { base: keyType }});\n      keyIdlType.tokens.separator = tokeniser.consume(\",\") || tokeniser.error(\"Missing comma after record key type\");\n      keyIdlType.type = typeName;\n      const valueType = type_with_extended_attributes(tokeniser, typeName) || tokeniser.error(\"Error parsing generic type record\");\n      ret.subtype.push(keyIdlType, valueType);\n      break;\n    }\n  }\n  if (!ret.idlType) tokeniser.error(`Error parsing generic type ${base.type}`);\n  ret.tokens.close = tokeniser.consume(\">\") || tokeniser.error(`Missing closing bracket after ${base.type}`);\n  return ret.this;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nfunction type_suffix(tokeniser, obj) {\n  const nullable = tokeniser.consume(\"?\");\n  if (nullable) {\n    obj.tokens.nullable = nullable;\n  }\n  if (tokeniser.probe(\"?\")) tokeniser.error(\"Can't nullable more than once\");\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nfunction single_type(tokeniser, typeName) {\n  let ret = generic_type(tokeniser, typeName) || primitive_type(tokeniser);\n  if (!ret) {\n    const base = tokeniser.consume(\"identifier\", ...stringTypes, ...typeNameKeywords);\n    if (!base) {\n      return;\n    }\n    ret = new Type({ source: tokeniser.source, tokens: { base } });\n    if (tokeniser.probe(\"<\")) tokeniser.error(`Unsupported generic type ${base.value}`);\n  }\n  if (ret.generic === \"Promise\" && tokeniser.probe(\"?\")) {\n    tokeniser.error(\"Promise type cannot be nullable\");\n  }\n  ret.type = typeName || null;\n  type_suffix(tokeniser, ret);\n  if (ret.nullable && ret.idlType === \"any\") tokeniser.error(\"Type `any` cannot be made nullable\");\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} type\n */\nfunction union_type(tokeniser, type) {\n  const tokens = {};\n  tokens.open = tokeniser.consume(\"(\");\n  if (!tokens.open) return;\n  const ret = autoParenter(new Type({ source: tokeniser.source, tokens }));\n  ret.type = type || null;\n  while (true) {\n    const typ = type_with_extended_attributes(tokeniser) || tokeniser.error(\"No type after open parenthesis or 'or' in union type\");\n    if (typ.idlType === \"any\") tokeniser.error(\"Type `any` cannot be included in a union type\");\n    if (typ.generic === \"Promise\") tokeniser.error(\"Type `Promise` cannot be included in a union type\");\n    ret.subtype.push(typ);\n    const or = tokeniser.consume(\"or\");\n    if (or) {\n      typ.tokens.separator = or;\n    }\n    else break;\n  }\n  if (ret.idlType.length < 2) {\n    tokeniser.error(\"At least two types are expected in a union type but found less\");\n  }\n  tokens.close = tokeniser.consume(\")\") || tokeniser.error(\"Unterminated union type\");\n  type_suffix(tokeniser, ret);\n  return ret.this;\n}\n\nexport class Type extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   * @param {string} typeName\n   */\n  static parse(tokeniser, typeName) {\n    return single_type(tokeniser, typeName) || union_type(tokeniser, typeName);\n  }\n\n  constructor({ source, tokens }) {\n    super({ source, tokens });\n    Object.defineProperty(this, \"subtype\", { value: [], writable: true });\n    this.extAttrs = new ExtendedAttributes({});\n  }\n\n  get generic() {\n    if (this.subtype.length && this.tokens.base) {\n      return this.tokens.base.value;\n    }\n    return \"\";\n  }\n  get nullable() {\n    return Boolean(this.tokens.nullable);\n  }\n  get union() {\n    return Boolean(this.subtype.length) && !this.tokens.base;\n  }\n  get idlType() {\n    if (this.subtype.length) {\n      return this.subtype;\n    }\n    // Adding prefixes/postfixes for \"unrestricted float\", etc.\n    const name = [\n      this.tokens.prefix,\n      this.tokens.base,\n      this.tokens.postfix\n    ].filter(t => t).map(t => t.value).join(\" \");\n    return unescape(name);\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n\n    if (this.idlType === \"void\") {\n      const message = `\\`void\\` is now replaced by \\`undefined\\`. Refer to the \\\n[relevant GitHub issue](https://github.com/heycam/webidl/issues/60) \\\nfor more information.`;\n      yield validationError(this.tokens.base, this, \"replace-void\", message, {\n        autofix: replaceVoid(this)\n      });\n    }\n\n    /*\n     * If a union is nullable, its subunions cannot include a dictionary\n     * If not, subunions may include dictionaries if each union is not nullable\n     */\n    const typedef = !this.union && defs.unique.get(this.idlType);\n    const target =\n      this.union ? this :\n      (typedef && typedef.type === \"typedef\") ? typedef.idlType :\n      undefined;\n    if (target && this.nullable) {\n      // do not allow any dictionary\n      const { reference } = idlTypeIncludesDictionary(target, defs) || {};\n      if (reference) {\n        const targetToken = (this.union ? reference : this).tokens.base;\n        const message = \"Nullable union cannot include a dictionary type.\";\n        yield validationError(targetToken, this, \"no-nullable-union-dict\", message);\n      }\n    } else {\n      // allow some dictionary\n      for (const subtype of this.subtype) {\n        yield* subtype.validate(defs);\n      }\n    }\n  }\n}\n\n/**\n * @param {Type} type\n */\nfunction replaceVoid(type) {\n  return () => {\n    type.tokens.base.value = \"undefined\";\n  };\n}\n","import { Base } from \"./base.js\";\nimport { const_data, const_value } from \"./helpers.js\";\n\nexport class Default extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const assign = tokeniser.consume(\"=\");\n    if (!assign) {\n      return null;\n    }\n    const def = const_value(tokeniser) || tokeniser.consume(\"string\", \"null\", \"[\", \"{\") || tokeniser.error(\"No value for default\");\n    const expression = [def];\n    if (def.type === \"[\") {\n      const close = tokeniser.consume(\"]\") || tokeniser.error(\"Default sequence value must be empty\");\n      expression.push(close);\n    } else if (def.type === \"{\") {\n      const close = tokeniser.consume(\"}\") || tokeniser.error(\"Default dictionary value must be empty\");\n      expression.push(close);\n    }\n    return new Default({ source: tokeniser.source, tokens: { assign }, expression });\n  }\n\n  constructor({ source, tokens, expression }) {\n    super({ source, tokens });\n    expression.parent = this;\n    Object.defineProperty(this, \"expression\", { value: expression });\n  }\n\n  get type() {\n    return const_data(this.expression[0]).type;\n  }\n  get value() {\n    return const_data(this.expression[0]).value;\n  }\n  get negative() {\n    return const_data(this.expression[0]).negative;\n  }\n}\n","// @ts-check\n\nimport { Base } from \"./base.js\";\nimport { Default } from \"./default.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport { unescape, type_with_extended_attributes, autoParenter, getFirstToken } from \"./helpers.js\";\nimport { argumentNameKeywords, Tokeniser } from \"../tokeniser.js\";\nimport { validationError } from \"../error.js\";\nimport { idlTypeIncludesDictionary, dictionaryIncludesRequiredField } from \"../validators/helpers.js\";\n\nexport class Argument extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const start_position = tokeniser.position;\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    const ret = autoParenter(new Argument({ source: tokeniser.source, tokens }));\n    ret.extAttrs = ExtendedAttributes.parse(tokeniser);\n    tokens.optional = tokeniser.consume(\"optional\");\n    ret.idlType = type_with_extended_attributes(tokeniser, \"argument-type\");\n    if (!ret.idlType) {\n      return tokeniser.unconsume(start_position);\n    }\n    if (!tokens.optional) {\n      tokens.variadic = tokeniser.consume(\"...\");\n    }\n    tokens.name = tokeniser.consume(\"identifier\", ...argumentNameKeywords);\n    if (!tokens.name) {\n      return tokeniser.unconsume(start_position);\n    }\n    ret.default = tokens.optional ? Default.parse(tokeniser) : null;\n    return ret.this;\n  }\n\n  get type() {\n    return \"argument\";\n  }\n  get optional() {\n    return !!this.tokens.optional;\n  }\n  get variadic() {\n    return !!this.tokens.variadic;\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  /**\n   * @param {import(\"../validator.js\").Definitions} defs\n   */\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n    const result = idlTypeIncludesDictionary(this.idlType, defs, { useNullableInner: true });\n    if (result) {\n      if (this.idlType.nullable) {\n        const message = `Dictionary arguments cannot be nullable.`;\n        yield validationError(this.tokens.name, this, \"no-nullable-dict-arg\", message);\n      } else if (!this.optional) {\n        if (this.parent && !dictionaryIncludesRequiredField(result.dictionary, defs) && isLastRequiredArgument(this)) {\n          const message = `Dictionary argument must be optional if it has no required fields`;\n          yield validationError(this.tokens.name, this, \"dict-arg-optional\", message, {\n            autofix: autofixDictionaryArgumentOptionality(this)\n          });\n        }\n      } else if (!this.default) {\n        const message = `Optional dictionary arguments must have a default value of \\`{}\\`.`;\n        yield validationError(this.tokens.name, this, \"dict-arg-default\", message, {\n          autofix: autofixOptionalDictionaryDefaultValue(this)\n        });\n      }\n    }\n  }\n}\n\n/**\n * @param {Argument} arg\n */\nfunction isLastRequiredArgument(arg) {\n  const list = arg.parent.arguments || arg.parent.list;\n  const index = list.indexOf(arg);\n  const requiredExists = list.slice(index + 1).some(a => !a.optional);\n  return !requiredExists;\n}\n\n/**\n * @param {Argument} arg\n */\nfunction autofixDictionaryArgumentOptionality(arg) {\n  return () => {\n    const firstToken = getFirstToken(arg.idlType);\n    arg.tokens.optional = { type: \"optional\", value: \"optional\", trivia: firstToken.trivia };\n    firstToken.trivia = \" \";\n    autofixOptionalDictionaryDefaultValue(arg)();\n  };\n}\n\n/**\n * @param {Argument} arg\n */\nfunction autofixOptionalDictionaryDefaultValue(arg) {\n  return () => {\n    arg.default = Default.parse(new Tokeniser(\" = {}\"));\n  };\n}\n","import { Base } from \"./base.js\";\nimport { return_type, argument_list, unescape, autoParenter } from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\n\nexport class Operation extends Base {\n  /**\n   * @typedef {import(\"../tokeniser.js\").Token} Token\n   *\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {object} [options]\n   * @param {Token} [options.special]\n   * @param {Token} [options.regular]\n   */\n  static parse(tokeniser, { special, regular } = {}) {\n    const tokens = { special };\n    const ret = autoParenter(new Operation({ source: tokeniser.source, tokens }));\n    if (special && special.value === \"stringifier\") {\n      tokens.termination = tokeniser.consume(\";\");\n      if (tokens.termination) {\n        ret.arguments = [];\n        return ret;\n      }\n    }\n    if (!special && !regular) {\n      tokens.special = tokeniser.consume(\"getter\", \"setter\", \"deleter\");\n    }\n    ret.idlType = return_type(tokeniser) || tokeniser.error(\"Missing return type\");\n    tokens.name = tokeniser.consume(\"identifier\", \"includes\");\n    tokens.open = tokeniser.consume(\"(\") || tokeniser.error(\"Invalid operation\");\n    ret.arguments = argument_list(tokeniser);\n    tokens.close = tokeniser.consume(\")\") || tokeniser.error(\"Unterminated operation\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated operation, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"operation\";\n  }\n  get name() {\n    const { name } = this.tokens;\n    if (!name) {\n      return \"\";\n    }\n    return unescape(name.value);\n  }\n  get special() {\n    if (!this.tokens.special) {\n      return \"\";\n    }\n    return this.tokens.special.value;\n  }\n\n  *validate(defs) {\n    if (!this.name && [\"\", \"static\"].includes(this.special)) {\n      const message = `Regular or static operations must have both a return type and an identifier.`;\n      yield validationError(this.tokens.open, this, \"incomplete-op\", message);\n    }\n    if (this.idlType) {\n      yield* this.idlType.validate(defs);\n    }\n    for (const argument of this.arguments) {\n      yield* argument.validate(defs);\n    }\n  }\n}\n","import { Base } from \"./base.js\";\nimport { type_with_extended_attributes, unescape, autoParenter } from \"./helpers.js\";\n\nexport class Attribute extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, { special, noInherit = false, readonly = false } = {}) {\n    const start_position = tokeniser.position;\n    const tokens = { special };\n    const ret = autoParenter(new Attribute({ source: tokeniser.source, tokens }));\n    if (!special && !noInherit) {\n      tokens.special = tokeniser.consume(\"inherit\");\n    }\n    if (ret.special === \"inherit\" && tokeniser.probe(\"readonly\")) {\n      tokeniser.error(\"Inherited attributes cannot be read-only\");\n    }\n    tokens.readonly = tokeniser.consume(\"readonly\");\n    if (readonly && !tokens.readonly && tokeniser.probe(\"attribute\")) {\n      tokeniser.error(\"Attributes must be readonly in this context\");\n    }\n    tokens.base = tokeniser.consume(\"attribute\");\n    if (!tokens.base) {\n      tokeniser.unconsume(start_position);\n      return;\n    }\n    ret.idlType = type_with_extended_attributes(tokeniser, \"attribute-type\") || tokeniser.error(\"Attribute lacks a type\");\n    switch (ret.idlType.generic) {\n      case \"sequence\":\n      case \"record\": tokeniser.error(`Attributes cannot accept ${ret.idlType.generic} types`);\n    }\n    tokens.name = tokeniser.consume(\"identifier\", \"async\", \"required\") || tokeniser.error(\"Attribute lacks a name\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated attribute, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"attribute\";\n  }\n  get special() {\n    if (!this.tokens.special) {\n      return \"\";\n    }\n    return this.tokens.special.value;\n  }\n  get readonly() {\n    return !!this.tokens.readonly;\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    yield* this.idlType.validate(defs);\n  }\n}\n","import { Type } from \"./type.js\";\nimport { Argument } from \"./argument.js\";\nimport { ExtendedAttributes, SimpleExtendedAttribute } from \"./extended-attributes.js\";\nimport { Operation } from \"./operation.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Tokeniser } from \"../tokeniser.js\";\n\n/**\n * @param {string} identifier\n */\nexport function unescape(identifier) {\n  return identifier.startsWith('_') ? identifier.slice(1) : identifier;\n}\n\n/**\n * Parses comma-separated list\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {object} args\n * @param {Function} args.parser parser function for each item\n * @param {boolean} [args.allowDangler] whether to allow dangling comma\n * @param {string} [args.listName] the name to be shown on error messages\n */\nexport function list(tokeniser, { parser, allowDangler, listName = \"list\" }) {\n  const first = parser(tokeniser);\n  if (!first) {\n    return [];\n  }\n  first.tokens.separator = tokeniser.consume(\",\");\n  const items = [first];\n  while (first.tokens.separator) {\n    const item = parser(tokeniser);\n    if (!item) {\n      if (!allowDangler) {\n        tokeniser.error(`Trailing comma in ${listName}`);\n      }\n      break;\n    }\n    item.tokens.separator = tokeniser.consume(\",\");\n    items.push(item);\n    if (!item.tokens.separator) break;\n  }\n  return items;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function const_value(tokeniser) {\n  return tokeniser.consume(\"true\", \"false\", \"Infinity\", \"-Infinity\", \"NaN\", \"decimal\", \"integer\");\n}\n\n/**\n * @param {object} token\n * @param {string} token.type\n * @param {string} token.value\n */\nexport function const_data({ type, value }) {\n  switch (type) {\n    case \"true\":\n    case \"false\":\n      return { type: \"boolean\", value: type === \"true\" };\n    case \"Infinity\":\n    case \"-Infinity\":\n      return { type: \"Infinity\", negative: type.startsWith(\"-\") };\n    case \"[\":\n      return { type: \"sequence\", value: [] };\n    case \"{\":\n      return { type: \"dictionary\" };\n    case \"decimal\":\n    case \"integer\":\n      return { type: \"number\", value };\n    case \"string\":\n      return { type: \"string\", value: value.slice(1, -1) };\n    default:\n      return { type };\n  }\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function primitive_type(tokeniser) {\n  function integer_type() {\n    const prefix = tokeniser.consume(\"unsigned\");\n    const base = tokeniser.consume(\"short\", \"long\");\n    if (base) {\n      const postfix = tokeniser.consume(\"long\");\n      return new Type({ source, tokens: { prefix, base, postfix } });\n    }\n    if (prefix) tokeniser.error(\"Failed to parse integer type\");\n  }\n\n  function decimal_type() {\n    const prefix = tokeniser.consume(\"unrestricted\");\n    const base = tokeniser.consume(\"float\", \"double\");\n    if (base) {\n      return new Type({ source, tokens: { prefix, base } });\n    }\n    if (prefix) tokeniser.error(\"Failed to parse float type\");\n  }\n\n  const { source } = tokeniser;\n  const num_type = integer_type(tokeniser) || decimal_type(tokeniser);\n  if (num_type) return num_type;\n  const base = tokeniser.consume(\"boolean\", \"byte\", \"octet\", \"undefined\");\n  if (base) {\n    return new Type({ source, tokens: { base } });\n  }\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function argument_list(tokeniser) {\n  return list(tokeniser, { parser: Argument.parse, listName: \"arguments list\" });\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nexport function type_with_extended_attributes(tokeniser, typeName) {\n  const extAttrs = ExtendedAttributes.parse(tokeniser);\n  const ret = Type.parse(tokeniser, typeName);\n  if (ret) autoParenter(ret).extAttrs = extAttrs;\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nexport function return_type(tokeniser, typeName) {\n  const typ = Type.parse(tokeniser, typeName || \"return-type\");\n  if (typ) {\n    return typ;\n  }\n  const voidToken = tokeniser.consume(\"void\");\n  if (voidToken) {\n    const ret = new Type({ source: tokeniser.source, tokens: { base: voidToken } });\n    ret.type = \"return-type\";\n    return ret;\n  }\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function stringifier(tokeniser) {\n  const special = tokeniser.consume(\"stringifier\");\n  if (!special) return;\n  const member = Attribute.parse(tokeniser, { special }) ||\n    Operation.parse(tokeniser, { special }) ||\n    tokeniser.error(\"Unterminated stringifier\");\n  return member;\n}\n\n/**\n * @param {string} str\n */\nexport function getLastIndentation(str) {\n  const lines = str.split(\"\\n\");\n  // the first line visually binds to the preceding token\n  if (lines.length) {\n    const match = lines[lines.length - 1].match(/^\\s+/);\n    if (match) {\n      return match[0];\n    }\n  }\n  return \"\";\n}\n\n/**\n * @param {string} parentTrivia\n */\nexport function getMemberIndentation(parentTrivia) {\n  const indentation = getLastIndentation(parentTrivia);\n  const indentCh = indentation.includes(\"\\t\") ? \"\\t\" : \"  \";\n  return indentation + indentCh;\n}\n\n/**\n * @param {object} def\n * @param {import(\"./extended-attributes.js\").ExtendedAttributes} def.extAttrs\n */\nexport function autofixAddExposedWindow(def) {\n  return () => {\n    if (def.extAttrs.length){\n      const tokeniser = new Tokeniser(\"Exposed=Window,\");\n      const exposed = SimpleExtendedAttribute.parse(tokeniser);\n      exposed.tokens.separator = tokeniser.consume(\",\");\n      const existing = def.extAttrs[0];\n      if (!/^\\s/.test(existing.tokens.name.trivia)) {\n        existing.tokens.name.trivia = ` ${existing.tokens.name.trivia}`;\n      }\n      def.extAttrs.unshift(exposed);\n    } else {\n      autoParenter(def).extAttrs = ExtendedAttributes.parse(new Tokeniser(\"[Exposed=Window]\"));\n      const trivia = def.tokens.base.trivia;\n      def.extAttrs.tokens.open.trivia = trivia;\n      def.tokens.base.trivia = `\\n${getLastIndentation(trivia)}`;\n    }\n  };\n}\n\n/**\n * Get the first syntax token for the given IDL object.\n * @param {*} data\n */\nexport function getFirstToken(data) {\n  if (data.extAttrs.length) {\n    return data.extAttrs.tokens.open;\n  }\n  if (data.type === \"operation\" && !data.special) {\n    return getFirstToken(data.idlType);\n  }\n  const tokens = Object.values(data.tokens).sort((x, y) => x.index - y.index);\n  return tokens[0];\n}\n\n/**\n * @template T\n * @param {T[]} array\n * @param {(item: T) => boolean} predicate\n */\nexport function findLastIndex(array, predicate) {\n  const index = array.slice().reverse().findIndex(predicate);\n  if (index === -1) {\n    return index;\n  }\n  return array.length - index - 1;\n}\n\n/**\n * Returns a proxy that auto-assign `parent` field.\n * @template T\n * @param {T} data\n * @param {*} [parent] The object that will be assigned to `parent`.\n *                     If absent, it will be `data` by default.\n * @return {T}\n */\nexport function autoParenter(data, parent) {\n  if (!parent) {\n    // Defaults to `data` unless specified otherwise.\n    parent = data;\n  }\n  if (!data) {\n    // This allows `autoParenter(undefined)` which again allows\n    // `autoParenter(parse())` where the function may return nothing.\n    return data;\n  }\n  return new Proxy(data, {\n    get(target, p) {\n      const value = target[p];\n      if (Array.isArray(value)) {\n        // Wraps the array so that any added items will also automatically\n        // get their `parent` values.\n        return autoParenter(value, target);\n      }\n      return value;\n    },\n    set(target, p, value) {\n      target[p] = value;\n      if (!value) {\n        return true;\n      } else if (Array.isArray(value)) {\n        // Assigning an array will add `parent` to its items.\n        for (const item of value) {\n          if (typeof item.parent !== \"undefined\") {\n            item.parent = parent;\n          }\n        }\n      } else if (typeof value.parent !== \"undefined\") {\n        value.parent = parent;\n      }\n      return true;\n    }\n  });\n}\n","import { syntaxError } from \"./error.js\";\nimport { unescape } from \"./productions/helpers.js\";\n\n// These regular expressions use the sticky flag so they will only match at\n// the current location (ie. the offset of lastIndex).\nconst tokenRe = {\n  // This expression uses a lookahead assertion to catch false matches\n  // against integers early.\n  \"decimal\": /-?(?=[0-9]*\\.|[0-9]+[eE])(([0-9]+\\.[0-9]*|[0-9]*\\.[0-9]+)([Ee][-+]?[0-9]+)?|[0-9]+[Ee][-+]?[0-9]+)/y,\n  \"integer\": /-?(0([Xx][0-9A-Fa-f]+|[0-7]*)|[1-9][0-9]*)/y,\n  \"identifier\": /[_-]?[A-Za-z][0-9A-Z_a-z-]*/y,\n  \"string\": /\"[^\"]*\"/y,\n  \"whitespace\": /[\\t\\n\\r ]+/y,\n  \"comment\": /((\\/(\\/.*|\\*([^*]|\\*[^/])*\\*\\/)[\\t\\n\\r ]*)+)/y,\n  \"other\": /[^\\t\\n\\r 0-9A-Za-z]/y\n};\n\nexport const typeNameKeywords = [\n  \"ArrayBuffer\",\n  \"DataView\",\n  \"Int8Array\",\n  \"Int16Array\",\n  \"Int32Array\",\n  \"Uint8Array\",\n  \"Uint16Array\",\n  \"Uint32Array\",\n  \"Uint8ClampedArray\",\n  \"Float32Array\",\n  \"Float64Array\",\n  \"any\",\n  \"object\",\n  \"symbol\"\n];\n\nexport const stringTypes = [\n  \"ByteString\",\n  \"DOMString\",\n  \"USVString\"\n];\n\nexport const argumentNameKeywords = [\n  \"async\",\n  \"attribute\",\n  \"callback\",\n  \"const\",\n  \"constructor\",\n  \"deleter\",\n  \"dictionary\",\n  \"enum\",\n  \"getter\",\n  \"includes\",\n  \"inherit\",\n  \"interface\",\n  \"iterable\",\n  \"maplike\",\n  \"namespace\",\n  \"partial\",\n  \"required\",\n  \"setlike\",\n  \"setter\",\n  \"static\",\n  \"stringifier\",\n  \"typedef\",\n  \"unrestricted\"\n];\n\nconst nonRegexTerminals = [\n  \"-Infinity\",\n  \"FrozenArray\",\n  \"Infinity\",\n  \"NaN\",\n  \"ObservableArray\",\n  \"Promise\",\n  \"boolean\",\n  \"byte\",\n  \"double\",\n  \"false\",\n  \"float\",\n  \"long\",\n  \"mixin\",\n  \"null\",\n  \"octet\",\n  \"optional\",\n  \"or\",\n  \"readonly\",\n  \"record\",\n  \"sequence\",\n  \"short\",\n  \"true\",\n  \"undefined\",\n  \"unsigned\",\n  \"void\"\n].concat(argumentNameKeywords, stringTypes, typeNameKeywords);\n\nconst punctuations = [\n  \"(\",\n  \")\",\n  \",\",\n  \"...\",\n  \":\",\n  \";\",\n  \"<\",\n  \"=\",\n  \">\",\n  \"?\",\n  \"[\",\n  \"]\",\n  \"{\",\n  \"}\"\n];\n\nconst reserved = [\n  // \"constructor\" is now a keyword\n  \"_constructor\",\n  \"toString\",\n  \"_toString\",\n];\n\n/**\n * @typedef {ArrayItemType<ReturnType<typeof tokenise>>} Token\n * @param {string} str\n */\nfunction tokenise(str) {\n  const tokens = [];\n  let lastCharIndex = 0;\n  let trivia = \"\";\n  let line = 1;\n  let index = 0;\n  while (lastCharIndex < str.length) {\n    const nextChar = str.charAt(lastCharIndex);\n    let result = -1;\n\n    if (/[\\t\\n\\r ]/.test(nextChar)) {\n      result = attemptTokenMatch(\"whitespace\", { noFlushTrivia: true });\n    } else if (nextChar === '/') {\n      result = attemptTokenMatch(\"comment\", { noFlushTrivia: true });\n    }\n\n    if (result !== -1) {\n      const currentTrivia = tokens.pop().value;\n      line += (currentTrivia.match(/\\n/g) || []).length;\n      trivia += currentTrivia;\n      index -= 1;\n    } else if (/[-0-9.A-Z_a-z]/.test(nextChar)) {\n      result = attemptTokenMatch(\"decimal\");\n      if (result === -1) {\n        result = attemptTokenMatch(\"integer\");\n      }\n      if (result === -1) {\n        result = attemptTokenMatch(\"identifier\");\n        const lastIndex = tokens.length - 1;\n        const token = tokens[lastIndex];\n        if (result !== -1) {\n          if (reserved.includes(token.value)) {\n            const message = `${unescape(token.value)} is a reserved identifier and must not be used.`;\n            throw new WebIDLParseError(syntaxError(tokens, lastIndex, null, message));\n          } else if (nonRegexTerminals.includes(token.value)) {\n            token.type = token.value;\n          }\n        }\n      }\n    } else if (nextChar === '\"') {\n      result = attemptTokenMatch(\"string\");\n    }\n\n    for (const punctuation of punctuations) {\n      if (str.startsWith(punctuation, lastCharIndex)) {\n        tokens.push({ type: punctuation, value: punctuation, trivia, line, index });\n        trivia = \"\";\n        lastCharIndex += punctuation.length;\n        result = lastCharIndex;\n        break;\n      }\n    }\n\n    // other as the last try\n    if (result === -1) {\n      result = attemptTokenMatch(\"other\");\n    }\n    if (result === -1) {\n      throw new Error(\"Token stream not progressing\");\n    }\n    lastCharIndex = result;\n    index += 1;\n  }\n\n  // remaining trivia as eof\n  tokens.push({\n    type: \"eof\",\n    value: \"\",\n    trivia\n  });\n\n  return tokens;\n\n  /**\n   * @param {keyof typeof tokenRe} type\n   * @param {object} options\n   * @param {boolean} [options.noFlushTrivia]\n   */\n  function attemptTokenMatch(type, { noFlushTrivia } = {}) {\n    const re = tokenRe[type];\n    re.lastIndex = lastCharIndex;\n    const result = re.exec(str);\n    if (result) {\n      tokens.push({ type, value: result[0], trivia, line, index });\n      if (!noFlushTrivia) {\n        trivia = \"\";\n      }\n      return re.lastIndex;\n    }\n    return -1;\n  }\n}\n\nexport class Tokeniser {\n  /**\n   * @param {string} idl\n   */\n  constructor(idl) {\n    this.source = tokenise(idl);\n    this.position = 0;\n  }\n\n  /**\n   * @param {string} message\n   * @return {never}\n   */\n  error(message) {\n    throw new WebIDLParseError(syntaxError(this.source, this.position, this.current, message));\n  }\n\n  /**\n   * @param {string} type\n   */\n  probe(type) {\n    return this.source.length > this.position && this.source[this.position].type === type;\n  }\n\n  /**\n   * @param  {...string} candidates\n   */\n  consume(...candidates) {\n    for (const type of candidates) {\n      if (!this.probe(type)) continue;\n      const token = this.source[this.position];\n      this.position++;\n      return token;\n    }\n  }\n\n  /**\n   * @param {number} position\n   */\n  unconsume(position) {\n    this.position = position;\n  }\n}\n\nexport class WebIDLParseError extends Error {\n  /**\n   * @param {object} options\n   * @param {string} options.message\n   * @param {string} options.bareMessage\n   * @param {string} options.context\n   * @param {number} options.line\n   * @param {*} options.sourceName\n   * @param {string} options.input\n   * @param {*[]} options.tokens\n   */\n  constructor({ message, bareMessage, context, line, sourceName, input, tokens }) {\n    super(message);\n\n    this.name = \"WebIDLParseError\"; // not to be mangled\n    this.bareMessage = bareMessage;\n    this.context = context;\n    this.line = line;\n    this.sourceName = sourceName;\n    this.input = input;\n    this.tokens = tokens;\n  }\n}\n","import { list, unescape, autoParenter } from \"./helpers.js\";\nimport { Token } from \"./token.js\";\nimport { Base } from \"./base.js\";\n\nclass EnumValue extends Token {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const value = tokeniser.consume(\"string\");\n    if (value) {\n      return new EnumValue({ source: tokeniser.source, tokens: { value } });\n    }\n  }\n\n  get type() {\n    return \"enum-value\";\n  }\n  get value() {\n    return super.value.slice(1, -1);\n  }\n}\n\nexport class Enum extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    tokens.base = tokeniser.consume(\"enum\");\n    if (!tokens.base) {\n      return;\n    }\n    tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(\"No name for enum\");\n    const ret = autoParenter(new Enum({ source: tokeniser.source, tokens }));\n    tokeniser.current = ret.this;\n    tokens.open = tokeniser.consume(\"{\") || tokeniser.error(\"Bodyless enum\");\n    ret.values = list(tokeniser, {\n      parser: EnumValue.parse,\n      allowDangler: true,\n      listName: \"enumeration\"\n    });\n    if (tokeniser.probe(\"string\")) {\n      tokeniser.error(\"No comma between enum values\");\n    }\n    tokens.close = tokeniser.consume(\"}\") || tokeniser.error(\"Unexpected value in enum\");\n    if (!ret.values.length) {\n      tokeniser.error(\"No value in enum\");\n    }\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"No semicolon after enum\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"enum\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n}\n","// @ts-check\n\nimport { Base } from \"./base.js\";\nimport { unescape } from \"./helpers.js\";\n\nexport class Includes extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const target = tokeniser.consume(\"identifier\");\n    if (!target) {\n      return;\n    }\n    const tokens = { target };\n    tokens.includes = tokeniser.consume(\"includes\");\n    if (!tokens.includes) {\n      tokeniser.unconsume(target.index);\n      return;\n    }\n    tokens.mixin = tokeniser.consume(\"identifier\") || tokeniser.error(\"Incomplete includes statement\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"No terminating ; for includes statement\");\n    return new Includes({ source: tokeniser.source, tokens });\n  }\n\n  get type() {\n    return \"includes\";\n  }\n  get target() {\n    return unescape(this.tokens.target.value);\n  }\n  get includes() {\n    return unescape(this.tokens.mixin.value);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { type_with_extended_attributes, unescape, autoParenter } from \"./helpers.js\";\n\nexport class Typedef extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    const ret = autoParenter(new Typedef({ source: tokeniser.source, tokens }));\n    tokens.base = tokeniser.consume(\"typedef\");\n    if (!tokens.base) {\n      return;\n    }\n    ret.idlType = type_with_extended_attributes(tokeniser, \"typedef-type\") || tokeniser.error(\"Typedef lacks a type\");\n    tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(\"Typedef lacks a name\");\n    tokeniser.current = ret.this;\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated typedef, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"typedef\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { return_type, argument_list, unescape, autoParenter } from \"./helpers.js\";\n\nexport class CallbackFunction extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, base) {\n    const tokens = { base };\n    const ret = autoParenter(new CallbackFunction({ source: tokeniser.source, tokens }));\n    tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(\"Callback lacks a name\");\n    tokeniser.current = ret.this;\n    tokens.assign = tokeniser.consume(\"=\") || tokeniser.error(\"Callback lacks an assignment\");\n    ret.idlType = return_type(tokeniser) || tokeniser.error(\"Callback lacks a return type\");\n    tokens.open = tokeniser.consume(\"(\") || tokeniser.error(\"Callback lacks parentheses for arguments\");\n    ret.arguments = argument_list(tokeniser);\n    tokens.close = tokeniser.consume(\")\") || tokeniser.error(\"Unterminated callback\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated callback, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"callback\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    yield* this.idlType.validate(defs);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport { unescape, autoParenter } from \"./helpers.js\";\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nfunction inheritance(tokeniser) {\n  const colon = tokeniser.consume(\":\");\n  if (!colon) {\n    return {};\n  }\n  const inheritance = tokeniser.consume(\"identifier\") || tokeniser.error(\"Inheritance lacks a type\");\n  return { colon, inheritance };\n}\n\nexport class Container extends Base {\n    /**\n     * @template T\n     * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n     * @param {T} instance\n     * @param {*} args\n     */\n    static parse(tokeniser, instance, { type, inheritable, allowedMembers }) {\n      const { tokens } = instance;\n      tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(`Missing name in ${instance.type}`);\n      tokeniser.current = instance;\n      instance = autoParenter(instance);\n      if (inheritable) {\n        Object.assign(tokens, inheritance(tokeniser));\n      }\n      tokens.open = tokeniser.consume(\"{\") || tokeniser.error(`Bodyless ${type}`);\n      instance.members = [];\n      while (true) {\n        tokens.close = tokeniser.consume(\"}\");\n        if (tokens.close) {\n          tokens.termination = tokeniser.consume(\";\") || tokeniser.error(`Missing semicolon after ${type}`);\n          return instance.this;\n        }\n        const ea = ExtendedAttributes.parse(tokeniser);\n        let mem;\n        for (const [parser, ...args] of allowedMembers) {\n          mem = autoParenter(parser(tokeniser, ...args));\n          if (mem) {\n            break;\n          }\n        }\n        if (!mem) {\n          tokeniser.error(\"Unknown member\");\n        }\n        mem.extAttrs = ea;\n        instance.members.push(mem.this);\n      }\n    }\n\n    get partial() {\n      return !!this.tokens.partial;\n    }\n    get name() {\n      return unescape(this.tokens.name.value);\n    }\n    get inheritance() {\n      if (!this.tokens.inheritance) {\n        return null;\n      }\n      return unescape(this.tokens.inheritance.value);\n    }\n\n    *validate(defs) {\n      for (const member of this.members) {\n        if (member.validate) {\n          yield* member.validate(defs);\n        }\n      }\n    }\n  }\n","import { Base } from \"./base.js\";\nimport { Type } from \"./type.js\";\nimport { const_data, const_value, primitive_type, autoParenter, unescape } from \"./helpers.js\";\n\nexport class Constant extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    tokens.base = tokeniser.consume(\"const\");\n    if (!tokens.base) {\n      return;\n    }\n    let idlType = primitive_type(tokeniser);\n    if (!idlType) {\n      const base = tokeniser.consume(\"identifier\") || tokeniser.error(\"Const lacks a type\");\n      idlType = new Type({ source: tokeniser.source, tokens: { base } });\n    }\n    if (tokeniser.probe(\"?\")) {\n      tokeniser.error(\"Unexpected nullable constant type\");\n    }\n    idlType.type = \"const-type\";\n    tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(\"Const lacks a name\");\n    tokens.assign = tokeniser.consume(\"=\") || tokeniser.error(\"Const lacks value assignment\");\n    tokens.value = const_value(tokeniser) || tokeniser.error(\"Const lacks a value\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated const, expected `;`\");\n    const ret = new Constant({ source: tokeniser.source, tokens });\n    autoParenter(ret).idlType = idlType;\n    return ret;\n  }\n\n  get type() {\n    return \"const\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n  get value() {\n    return const_data(this.tokens.value);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { type_with_extended_attributes, autoParenter, argument_list } from \"./helpers.js\";\n\nexport class IterableLike extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const start_position = tokeniser.position;\n    const tokens = {};\n    const ret = autoParenter(new IterableLike({ source: tokeniser.source, tokens }));\n    tokens.readonly = tokeniser.consume(\"readonly\");\n    if (!tokens.readonly) {\n      tokens.async = tokeniser.consume(\"async\");\n    }\n    tokens.base =\n      tokens.readonly ? tokeniser.consume(\"maplike\", \"setlike\") :\n      tokens.async ? tokeniser.consume(\"iterable\") :\n      tokeniser.consume(\"iterable\", \"maplike\", \"setlike\");\n    if (!tokens.base) {\n      tokeniser.unconsume(start_position);\n      return;\n    }\n\n    const { type } = ret;\n    const secondTypeRequired = type === \"maplike\";\n    const secondTypeAllowed = secondTypeRequired || type === \"iterable\";\n    const argumentAllowed = ret.async && type === \"iterable\";\n\n    tokens.open = tokeniser.consume(\"<\") || tokeniser.error(`Missing less-than sign \\`<\\` in ${type} declaration`);\n    const first = type_with_extended_attributes(tokeniser) || tokeniser.error(`Missing a type argument in ${type} declaration`);\n    ret.idlType = [first];\n    ret.arguments = [];\n\n    if (secondTypeAllowed) {\n      first.tokens.separator = tokeniser.consume(\",\");\n      if (first.tokens.separator) {\n        ret.idlType.push(type_with_extended_attributes(tokeniser));\n      }\n      else if (secondTypeRequired) {\n        tokeniser.error(`Missing second type argument in ${type} declaration`);\n      }\n    }\n\n    tokens.close = tokeniser.consume(\">\") || tokeniser.error(`Missing greater-than sign \\`>\\` in ${type} declaration`);\n\n    if (tokeniser.probe(\"(\")) {\n      if (argumentAllowed) {\n        tokens.argsOpen = tokeniser.consume(\"(\");\n        ret.arguments.push(...argument_list(tokeniser));\n        tokens.argsClose = tokeniser.consume(\")\") || tokeniser.error(\"Unterminated async iterable argument list\");\n      } else {\n        tokeniser.error(`Arguments are only allowed for \\`async iterable\\``);\n      }\n    }\n\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(`Missing semicolon after ${type} declaration`);\n\n    return ret.this;\n  }\n\n  get type() {\n    return this.tokens.base.value;\n  }\n  get readonly() {\n    return !!this.tokens.readonly;\n  }\n  get async() {\n    return !!this.tokens.async;\n  }\n\n  *validate(defs) {\n    for (const type of this.idlType) {\n      yield* type.validate(defs);\n    }\n    for (const argument of this.arguments) {\n      yield* argument.validate(defs);\n    }\n  }\n}\n","import { Base } from \"./base.js\";\nimport { argument_list, autoParenter } from \"./helpers.js\";\n\nexport class Constructor extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const base = tokeniser.consume(\"constructor\");\n    if (!base) {\n      return;\n    }\n    /** @type {Base[\"tokens\"]} */\n    const tokens = { base };\n    tokens.open = tokeniser.consume(\"(\") || tokeniser.error(\"No argument list in constructor\");\n    const args = argument_list(tokeniser);\n    tokens.close = tokeniser.consume(\")\") || tokeniser.error(\"Unterminated constructor\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"No semicolon after constructor\");\n    const ret = new Constructor({ source: tokeniser.source, tokens });\n    autoParenter(ret).arguments = args;\n    return ret;\n  }\n\n  get type() {\n    return \"constructor\";\n  }\n\n  *validate(defs) {\n    if (this.idlType) {\n      yield* this.idlType.validate(defs);\n    }\n    for (const argument of this.arguments) {\n      yield* argument.validate(defs);\n    }\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { Constant } from \"./constant.js\";\nimport { IterableLike } from \"./iterable.js\";\nimport { stringifier, autofixAddExposedWindow, getMemberIndentation, getLastIndentation, getFirstToken, findLastIndex, autoParenter } from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\nimport { checkInterfaceMemberDuplication } from \"../validators/interface.js\";\nimport { Constructor } from \"./constructor.js\";\nimport { Tokeniser } from \"../tokeniser.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nfunction static_member(tokeniser) {\n  const special = tokeniser.consume(\"static\");\n  if (!special) return;\n  const member = Attribute.parse(tokeniser, { special }) ||\n    Operation.parse(tokeniser, { special }) ||\n    tokeniser.error(\"No body in static member\");\n  return member;\n}\n\nexport class Interface extends Container {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, base, { partial = null } = {}) {\n    const tokens = { partial, base };\n    return Container.parse(tokeniser, new Interface({ source: tokeniser.source, tokens }), {\n      type: \"interface\",\n      inheritable: !partial,\n      allowedMembers: [\n        [Constant.parse],\n        [Constructor.parse],\n        [static_member],\n        [stringifier],\n        [IterableLike.parse],\n        [Attribute.parse],\n        [Operation.parse]\n      ]\n    });\n  }\n\n  get type() {\n    return \"interface\";\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    if (\n      !this.partial &&\n      this.extAttrs.every(extAttr => extAttr.name !== \"Exposed\") &&\n      this.extAttrs.every(extAttr => extAttr.name !== \"LegacyNoInterfaceObject\")\n    ) {\n      const message = `Interfaces must have \\`[Exposed]\\` extended attribute. \\\nTo fix, add, for example, \\`[Exposed=Window]\\`. Please also consider carefully \\\nif your interface should also be exposed in a Worker scope. Refer to the \\\n[WebIDL spec section on Exposed](https://heycam.github.io/webidl/#Exposed) \\\nfor more information.`;\n      yield validationError(this.tokens.name, this, \"require-exposed\", message, {\n        autofix: autofixAddExposedWindow(this)\n      });\n    }\n    const oldConstructors = this.extAttrs.filter(extAttr => extAttr.name === \"Constructor\");\n    for (const constructor of oldConstructors) {\n      const message = `Constructors should now be represented as a \\`constructor()\\` operation on the interface \\\ninstead of \\`[Constructor]\\` extended attribute. Refer to the \\\n[WebIDL spec section on constructor operations](https://heycam.github.io/webidl/#idl-constructors) \\\nfor more information.`;\n      yield validationError(constructor.tokens.name, this, \"constructor-member\", message, {\n        autofix: autofixConstructor(this, constructor)\n      });\n    }\n\n    const isGlobal = this.extAttrs.some(extAttr => extAttr.name === \"Global\");\n    if (isGlobal) {\n      const factoryFunctions = this.extAttrs.filter(extAttr => extAttr.name === \"LegacyFactoryFunction\");\n      for (const named of factoryFunctions) {\n        const message = `Interfaces marked as \\`[Global]\\` cannot have factory functions.`;\n        yield validationError(named.tokens.name, this, \"no-constructible-global\", message);\n      }\n\n      const constructors = this.members.filter(member => member.type === \"constructor\");\n      for (const named of constructors) {\n        const message = `Interfaces marked as \\`[Global]\\` cannot have constructors.`;\n        yield validationError(named.tokens.base, this, \"no-constructible-global\", message);\n      }\n    }\n\n    yield* super.validate(defs);\n    if (!this.partial) {\n      yield* checkInterfaceMemberDuplication(defs, this);\n    }\n  }\n}\n\nfunction autofixConstructor(interfaceDef, constructorExtAttr) {\n  interfaceDef = autoParenter(interfaceDef);\n  return () => {\n    const indentation = getLastIndentation(interfaceDef.extAttrs.tokens.open.trivia);\n    const memberIndent = interfaceDef.members.length ?\n      getLastIndentation(getFirstToken(interfaceDef.members[0]).trivia) :\n      getMemberIndentation(indentation);\n    const constructorOp = Constructor.parse(new Tokeniser(`\\n${memberIndent}constructor();`));\n    constructorOp.extAttrs = new ExtendedAttributes({});\n    autoParenter(constructorOp).arguments = constructorExtAttr.arguments;\n\n    const existingIndex = findLastIndex(interfaceDef.members, m => m.type === \"constructor\");\n    interfaceDef.members.splice(existingIndex + 1, 0, constructorOp);\n\n    const { close }  = interfaceDef.tokens;\n    if (!close.trivia.includes(\"\\n\")) {\n      close.trivia += `\\n${indentation}`;\n    }\n\n    const { extAttrs } = interfaceDef;\n    const index = extAttrs.indexOf(constructorExtAttr);\n    const removed = extAttrs.splice(index, 1);\n    if (!extAttrs.length) {\n      extAttrs.tokens.open = extAttrs.tokens.close = undefined;\n    } else if (extAttrs.length === index) {\n      extAttrs[index - 1].tokens.separator = undefined;\n    } else if (!extAttrs[index].tokens.name.trivia.trim()) {\n      extAttrs[index].tokens.name.trivia = removed[0].tokens.name.trivia;\n    }\n  };\n}\n","// @ts-check\n\nimport { validationError } from \"../error.js\";\n\nexport function* checkInterfaceMemberDuplication(defs, i) {\n  const opNames = new Set(getOperations(i).map(op => op.name));\n  const partials = defs.partials.get(i.name) || [];\n  const mixins = defs.mixinMap.get(i.name) || [];\n  for (const ext of [...partials, ...mixins]) {\n    const additions = getOperations(ext);\n    yield* forEachExtension(additions, opNames, ext, i);\n    for (const addition of additions) {\n      opNames.add(addition.name);\n    }\n  }\n\n  function* forEachExtension(additions, existings, ext, base) {\n    for (const addition of additions) {\n      const { name } = addition;\n      if (name && existings.has(name)) {\n        const message = `The operation \"${name}\" has already been defined for the base interface \"${base.name}\" either in itself or in a mixin`;\n        yield validationError(addition.tokens.name, ext, \"no-cross-overload\", message);\n      }\n    }\n  }\n\n  function getOperations(i) {\n    return i.members\n      .filter(({type}) => type === \"operation\");\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Constant } from \"./constant.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { stringifier } from \"./helpers.js\";\n\nexport class Mixin extends Container {\n  /**\n   * @typedef {import(\"../tokeniser.js\").Token} Token\n   *\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {Token} base\n   * @param {object} [options]\n   * @param {Token} [options.partial]\n   */\n  static parse(tokeniser, base, { partial } = {}) {\n    const tokens = { partial, base };\n    tokens.mixin = tokeniser.consume(\"mixin\");\n    if (!tokens.mixin) {\n      return;\n    }\n    return Container.parse(tokeniser, new Mixin({ source: tokeniser.source, tokens }), {\n      type: \"interface mixin\",\n      allowedMembers: [\n        [Constant.parse],\n        [stringifier],\n        [Attribute.parse, { noInherit: true }],\n        [Operation.parse, { regular: true }]\n      ]\n    });\n  }\n\n  get type() {\n    return \"interface mixin\";\n  }\n}\n","import { Base } from \"./base.js\";\nimport { unescape, type_with_extended_attributes, autoParenter } from \"./helpers.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport { Default } from \"./default.js\";\n\nexport class Field extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    const ret = autoParenter(new Field({ source: tokeniser.source, tokens }));\n    ret.extAttrs = ExtendedAttributes.parse(tokeniser);\n    tokens.required = tokeniser.consume(\"required\");\n    ret.idlType = type_with_extended_attributes(tokeniser, \"dictionary-type\") || tokeniser.error(\"Dictionary member lacks a type\");\n    tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(\"Dictionary member lacks a name\");\n    ret.default = Default.parse(tokeniser);\n    if (tokens.required && ret.default) tokeniser.error(\"Required member must not have a default\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated dictionary member, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"field\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n  get required() {\n    return !!this.tokens.required;\n  }\n\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n  }\n}\n","// @ts-check\n\nimport { Container } from \"./container.js\";\nimport { Field } from \"./field.js\";\n\nexport class Dictionary extends Container {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   * @param {object} [options]\n   * @param {import(\"../tokeniser.js\").Token} [options.partial]\n   */\n  static parse(tokeniser, { partial } = {}) {\n    const tokens = { partial };\n    tokens.base = tokeniser.consume(\"dictionary\");\n    if (!tokens.base) {\n      return;\n    }\n    return Container.parse(tokeniser, new Dictionary({ source: tokeniser.source, tokens }), {\n      type: \"dictionary\",\n      inheritable: !partial,\n      allowedMembers: [\n        [Field.parse],\n      ]\n    });\n  }\n\n  get type() {\n    return \"dictionary\";\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { validationError } from \"../error.js\";\nimport { autofixAddExposedWindow } from \"./helpers.js\";\n\nexport class Namespace extends Container {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   * @param {object} [options]\n   * @param {import(\"../tokeniser.js\").Token} [options.partial]\n   */\n  static parse(tokeniser, { partial } = {}) {\n    const tokens = { partial };\n    tokens.base = tokeniser.consume(\"namespace\");\n    if (!tokens.base) {\n      return;\n    }\n    return Container.parse(tokeniser, new Namespace({ source: tokeniser.source, tokens }), {\n      type: \"namespace\",\n      allowedMembers: [\n        [Attribute.parse, { noInherit: true, readonly: true }],\n        [Operation.parse, { regular: true }]\n      ]\n    });\n  }\n\n  get type() {\n    return \"namespace\";\n  }\n\n  *validate(defs) {\n    if (!this.partial && this.extAttrs.every(extAttr => extAttr.name !== \"Exposed\")) {\n      const message = `Namespaces must have [Exposed] extended attribute. \\\nTo fix, add, for example, [Exposed=Window]. Please also consider carefully \\\nif your namespace should also be exposed in a Worker scope. Refer to the \\\n[WebIDL spec section on Exposed](https://heycam.github.io/webidl/#Exposed) \\\nfor more information.`;\n      yield validationError(this.tokens.name, this, \"require-exposed\", message, {\n        autofix: autofixAddExposedWindow(this)\n      });\n    }\n    yield* super.validate(defs);\n  }\n}\n","// @ts-check\n\nimport { Container } from \"./container.js\";\nimport { Operation } from \"./operation.js\";\nimport { Constant } from \"./constant.js\";\n\nexport class CallbackInterface extends Container {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, callback, { partial = null } = {}) {\n    const tokens = { callback };\n    tokens.base = tokeniser.consume(\"interface\");\n    if (!tokens.base) {\n      return;\n    }\n    return Container.parse(tokeniser, new CallbackInterface({ source: tokeniser.source, tokens }), {\n      type: \"callback interface\",\n      inheritable: !partial,\n      allowedMembers: [\n        [Constant.parse],\n        [Operation.parse, { regular: true }]\n      ]\n    });\n  }\n\n  get type() {\n    return \"callback interface\";\n  }\n}\n","\"use strict\";\n\nimport { Tokeniser } from \"./tokeniser.js\";\nimport { Enum } from \"./productions/enum.js\";\nimport { Includes } from \"./productions/includes.js\";\nimport { ExtendedAttributes } from \"./productions/extended-attributes.js\";\nimport { Typedef } from \"./productions/typedef.js\";\nimport { CallbackFunction } from \"./productions/callback.js\";\nimport { Interface } from \"./productions/interface.js\";\nimport { Mixin } from \"./productions/mixin.js\";\nimport { Dictionary } from \"./productions/dictionary.js\";\nimport { Namespace } from \"./productions/namespace.js\";\nimport { CallbackInterface } from \"./productions/callback-interface.js\";\nimport { autoParenter } from \"./productions/helpers.js\";\n\n/**\n * @param {Tokeniser} tokeniser\n * @param {object} options\n * @param {boolean} [options.concrete]\n */\nfunction parseByTokens(tokeniser, options) {\n  const source = tokeniser.source;\n\n  function error(str) {\n    tokeniser.error(str);\n  }\n\n  function consume(...candidates) {\n    return tokeniser.consume(...candidates);\n  }\n\n  function callback() {\n    const callback = consume(\"callback\");\n    if (!callback) return;\n    if (tokeniser.probe(\"interface\")) {\n      return CallbackInterface.parse(tokeniser, callback);\n    }\n    return CallbackFunction.parse(tokeniser, callback);\n  }\n\n  function interface_(opts) {\n    const base = consume(\"interface\");\n    if (!base) return;\n    const ret = Mixin.parse(tokeniser, base, opts) ||\n      Interface.parse(tokeniser, base, opts) ||\n      error(\"Interface has no proper body\");\n    return ret;\n  }\n\n  function partial() {\n    const partial = consume(\"partial\");\n    if (!partial) return;\n    return Dictionary.parse(tokeniser, { partial }) ||\n      interface_({ partial }) ||\n      Namespace.parse(tokeniser, { partial }) ||\n      error(\"Partial doesn't apply to anything\");\n  }\n\n  function definition() {\n    return callback() ||\n      interface_() ||\n      partial() ||\n      Dictionary.parse(tokeniser) ||\n      Enum.parse(tokeniser) ||\n      Typedef.parse(tokeniser) ||\n      Includes.parse(tokeniser) ||\n      Namespace.parse(tokeniser);\n  }\n\n  function definitions() {\n    if (!source.length) return [];\n    const defs = [];\n    while (true) {\n      const ea = ExtendedAttributes.parse(tokeniser);\n      const def = definition();\n      if (!def) {\n        if (ea.length) error(\"Stray extended attributes\");\n        break;\n      }\n      autoParenter(def).extAttrs = ea;\n      defs.push(def);\n    }\n    const eof = consume(\"eof\");\n    if (options.concrete) {\n      defs.push(eof);\n    }\n    return defs;\n  }\n  const res = definitions();\n  if (tokeniser.position < source.length) error(\"Unrecognised tokens\");\n  return res;\n}\n\n/**\n * @param {string} str\n * @param {object} [options]\n * @param {*} [options.sourceName]\n * @param {boolean} [options.concrete]\n */\nexport function parse(str, options = {}) {\n  const tokeniser = new Tokeniser(str);\n  if (typeof options.sourceName !== \"undefined\") {\n    tokeniser.source.name = options.sourceName;\n  }\n  return parseByTokens(tokeniser, options);\n}\n","\"use strict\";\n\nfunction noop(arg) {\n  return arg;\n}\n\nconst templates = {\n  wrap: items => items.join(\"\"),\n  trivia: noop,\n  name: noop,\n  reference: noop,\n  type: noop,\n  generic: noop,\n  nameless: noop,\n  inheritance: noop,\n  definition: noop,\n  extendedAttribute: noop,\n  extendedAttributeReference: noop\n};\n\nexport function write(ast, { templates: ts = templates } = {}) {\n  ts = Object.assign({}, templates, ts);\n\n  function reference(raw, { unescaped, context }) {\n    if (!unescaped) {\n      unescaped = raw.startsWith(\"_\") ? raw.slice(1) : raw;\n    }\n    return ts.reference(raw, unescaped, context);\n  }\n\n  function token(t, wrapper = noop, ...args) {\n    if (!t) {\n      return \"\";\n    }\n    const value = wrapper(t.value, ...args);\n    return ts.wrap([ts.trivia(t.trivia), value]);\n  }\n\n  function reference_token(t, context) {\n    return token(t, reference, { context });\n  }\n\n  function name_token(t, arg) {\n    return token(t, ts.name, arg);\n  }\n\n  function type_body(it) {\n    if (it.union || it.generic) {\n      return ts.wrap([\n        token(it.tokens.base, ts.generic),\n        token(it.tokens.open),\n        ...it.subtype.map(type),\n        token(it.tokens.close)\n      ]);\n    }\n    const firstToken = it.tokens.prefix || it.tokens.base;\n    const prefix = it.tokens.prefix ? [\n      it.tokens.prefix.value,\n      ts.trivia(it.tokens.base.trivia)\n    ] : [];\n    const ref = reference(ts.wrap([\n      ...prefix,\n      it.tokens.base.value,\n      token(it.tokens.postfix)\n    ]), { unescaped: it.idlType, context: it });\n    return ts.wrap([ts.trivia(firstToken.trivia), ref]);\n  }\n  function type(it) {\n    return ts.wrap([\n      extended_attributes(it.extAttrs),\n      type_body(it),\n      token(it.tokens.nullable),\n      token(it.tokens.separator)\n    ]);\n  }\n  function default_(def) {\n    if (!def) {\n      return \"\";\n    }\n    return ts.wrap([\n      token(def.tokens.assign),\n      ...def.expression.map(t => token(t))\n    ]);\n  }\n  function argument(arg) {\n    return ts.wrap([\n      extended_attributes(arg.extAttrs),\n      token(arg.tokens.optional),\n      ts.type(type(arg.idlType)),\n      token(arg.tokens.variadic),\n      name_token(arg.tokens.name, { data: arg }),\n      default_(arg.default),\n      token(arg.tokens.separator)\n    ]);\n  }\n  function extended_attribute_listitem(str) {\n    return ts.wrap([\n      token(str.tokens.value),\n      token(str.tokens.separator)\n    ]);\n  }\n  function identifier(id, context) {\n    return ts.wrap([\n      reference_token(id.tokens.value, context),\n      token(id.tokens.separator)\n    ]);\n  }\n  function make_ext_at(it) {\n    const { rhsType } = it.params;\n    return ts.wrap([\n      ts.trivia(it.tokens.name.trivia),\n      ts.extendedAttribute(ts.wrap([\n        ts.extendedAttributeReference(it.name),\n        token(it.params.tokens.assign),\n        reference_token(it.params.tokens.secondaryName, it),\n        token(it.params.tokens.open),\n        ...!it.params.list ? [] :\n          it.params.list.map(\n            rhsType === \"identifier-list\" ? id => identifier(id, it) :\n            rhsType && rhsType.endsWith(\"-list\") ? extended_attribute_listitem :\n            argument\n          ),\n        token(it.params.tokens.close)\n      ])),\n      token(it.tokens.separator)\n    ]);\n  }\n  function extended_attributes(eats) {\n    if (!eats.length) return \"\";\n    return ts.wrap([\n      token(eats.tokens.open),\n      ...eats.map(make_ext_at),\n      token(eats.tokens.close)\n    ]);\n  }\n\n  function operation(it, parent) {\n    const body = it.idlType ? [\n      ts.type(type(it.idlType)),\n      name_token(it.tokens.name, { data: it, parent }),\n      token(it.tokens.open),\n      ts.wrap(it.arguments.map(argument)),\n      token(it.tokens.close),\n    ] : [];\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      it.tokens.name ? token(it.tokens.special) : token(it.tokens.special, ts.nameless, { data: it, parent }),\n      ...body,\n      token(it.tokens.termination)\n    ]), { data: it, parent });\n  }\n\n  function attribute(it, parent) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.special),\n      token(it.tokens.readonly),\n      token(it.tokens.base),\n      ts.type(type(it.idlType)),\n      name_token(it.tokens.name, { data: it, parent }),\n      token(it.tokens.termination)\n    ]), { data: it, parent });\n  }\n\n  function constructor(it, parent) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.base, ts.nameless, { data: it, parent }),\n      token(it.tokens.open),\n      ts.wrap(it.arguments.map(argument)),\n      token(it.tokens.close),\n      token(it.tokens.termination)\n    ]), { data: it, parent });\n  }\n\n  function inheritance(inh) {\n    if (!inh.tokens.inheritance) {\n      return \"\";\n    }\n    return ts.wrap([\n      token(inh.tokens.colon),\n      ts.trivia(inh.tokens.inheritance.trivia),\n      ts.inheritance(reference(inh.tokens.inheritance.value, { context: inh }))\n    ]);\n  }\n\n  function container(it) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.callback),\n      token(it.tokens.partial),\n      token(it.tokens.base),\n      token(it.tokens.mixin),\n      name_token(it.tokens.name, { data: it }),\n      inheritance(it),\n      token(it.tokens.open),\n      iterate(it.members, it),\n      token(it.tokens.close),\n      token(it.tokens.termination)\n    ]), { data: it });\n  }\n\n  function field(it, parent) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.required),\n      ts.type(type(it.idlType)),\n      name_token(it.tokens.name, { data: it, parent }),\n      default_(it.default),\n      token(it.tokens.termination)\n    ]), { data: it, parent });\n  }\n  function const_(it, parent) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.base),\n      ts.type(type(it.idlType)),\n      name_token(it.tokens.name, { data: it, parent }),\n      token(it.tokens.assign),\n      token(it.tokens.value),\n      token(it.tokens.termination)\n    ]), { data: it, parent });\n  }\n  function typedef(it) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.base),\n      ts.type(type(it.idlType)),\n      name_token(it.tokens.name, { data: it }),\n      token(it.tokens.termination)\n    ]), { data: it });\n  }\n  function includes(it) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      reference_token(it.tokens.target, it),\n      token(it.tokens.includes),\n      reference_token(it.tokens.mixin, it),\n      token(it.tokens.termination)\n    ]), { data: it });\n  }\n  function callback(it) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.base),\n      name_token(it.tokens.name, { data: it }),\n      token(it.tokens.assign),\n      ts.type(type(it.idlType)),\n      token(it.tokens.open),\n      ...it.arguments.map(argument),\n      token(it.tokens.close),\n      token(it.tokens.termination),\n    ]), { data: it });\n  }\n  function enum_(it) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.base),\n      name_token(it.tokens.name, { data: it }),\n      token(it.tokens.open),\n      iterate(it.values, it),\n      token(it.tokens.close),\n      token(it.tokens.termination)\n    ]), { data: it });\n  }\n  function enum_value(v, parent) {\n    return ts.wrap([\n      ts.trivia(v.tokens.value.trivia),\n      ts.definition(\n        ts.wrap(['\"', ts.name(v.value, { data: v, parent }), '\"']),\n        { data: v, parent }\n      ),\n      token(v.tokens.separator)\n    ]);\n  }\n  function iterable_like(it, parent) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.readonly),\n      token(it.tokens.async),\n      token(it.tokens.base, ts.generic),\n      token(it.tokens.open),\n      ts.wrap(it.idlType.map(type)),\n      token(it.tokens.close),\n      token(it.tokens.argsOpen),\n      ts.wrap(it.arguments.map(argument)),\n      token(it.tokens.argsClose),\n      token(it.tokens.termination)\n    ]), { data: it, parent });\n  }\n  function eof(it) {\n    return ts.trivia(it.trivia);\n  }\n\n  const table = {\n    interface: container,\n    \"interface mixin\": container,\n    namespace: container,\n    operation,\n    attribute,\n    constructor,\n    dictionary: container,\n    field,\n    const: const_,\n    typedef,\n    includes,\n    callback,\n    enum: enum_,\n    \"enum-value\": enum_value,\n    iterable: iterable_like,\n    maplike: iterable_like,\n    setlike: iterable_like,\n    \"callback interface\": container,\n    eof\n  };\n  function dispatch(it, parent) {\n    const dispatcher = table[it.type];\n    if (!dispatcher) {\n      throw new Error(`Type \"${it.type}\" is unsupported`);\n    }\n    return table[it.type](it, parent);\n  }\n  function iterate(things, parent) {\n    if (!things) return;\n    const results = things.map(thing => dispatch(thing, parent));\n    return ts.wrap(results);\n  }\n  return iterate(ast);\n}\n","\"use strict\";\n\nimport { validationError as error } from \"./error.js\";\n\nfunction getMixinMap(all, unique) {\n  const map = new Map();\n  const includes = all.filter(def => def.type === \"includes\");\n  for (const include of includes) {\n    const mixin = unique.get(include.includes);\n    if (!mixin) {\n      continue;\n    }\n    const array = map.get(include.target);\n    if (array) {\n      array.push(mixin);\n    } else {\n      map.set(include.target, [mixin]);\n    }\n  }\n  return map;\n}\n\n/**\n * @typedef {ReturnType<typeof groupDefinitions>} Definitions\n */\nfunction groupDefinitions(all) {\n  const unique = new Map();\n  const duplicates = new Set();\n  const partials = new Map();\n  for (const def of all) {\n    if (def.partial) {\n      const array = partials.get(def.name);\n      if (array) {\n        array.push(def);\n      } else {\n        partials.set(def.name, [def]);\n      }\n      continue;\n    }\n    if (!def.name) {\n      continue;\n    }\n    if (!unique.has(def.name)) {\n      unique.set(def.name, def);\n    } else {\n      duplicates.add(def);\n    }\n  }\n  return {\n    all,\n    unique,\n    partials,\n    duplicates,\n    mixinMap: getMixinMap(all, unique),\n    cache: {\n      typedefIncludesDictionary: new WeakMap(),\n      dictionaryIncludesRequiredField: new WeakMap()\n    },\n  };\n}\n\nfunction* checkDuplicatedNames({ unique, duplicates }) {\n  for (const dup of duplicates) {\n    const { name } = dup;\n    const message = `The name \"${name}\" of type \"${unique.get(name).type}\" was already seen`;\n    yield error(dup.tokens.name, dup, \"no-duplicate\", message);\n  }\n}\n\nfunction* validateIterable(ast) {\n  const defs = groupDefinitions(ast);\n  for (const def of defs.all) {\n    if (def.validate) {\n      yield* def.validate(defs);\n    }\n  }\n  yield* checkDuplicatedNames(defs);\n}\n\n// Remove this once all of our support targets expose `.flat()` by default\nfunction flatten(array) {\n  if (array.flat) {\n    return array.flat();\n  }\n  return [].concat(...array);\n}\n\n/**\n * @param {*} ast AST or array of ASTs\n */\nexport function validate(ast) {\n  return [...validateIterable(flatten(ast))];\n}\n"],"sourceRoot":""}